{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# System\n",
    "import os\n",
    "import json\n",
    "\n",
    "# Config\n",
    "import warnings\n",
    "\n",
    "# Web Scraping\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# Data\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "\n",
    "# View\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches\n",
    "import seaborn as sns\n",
    "from IPython.display import Image\n",
    "\n",
    "# ML\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn import metrics\n",
    "\n",
    "# ML Models\n",
    "from sklearn.dummy import DummyClassifier\n",
    "\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.svm import OneClassSVM\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Utilities Files\n",
    "def read_csv(name: str, index_label='id') -> pd.DataFrame:\n",
    "    return pd.read_csv('../data/' + name + '.csv', index_col=index_label)\n",
    "\n",
    "\n",
    "def save_csv(df: pd.DataFrame, name: str, index_label='id'):\n",
    "    df.to_csv('../data/' + name + '.csv', index_label=index_label)\n",
    "\n",
    "def show_image(name: str):\n",
    "    return Image(filename= '../images/' + name + '.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Development Flags\n",
    "SHOW_IN_RELEASE = True\n",
    "SHOW_IN_DEVELOPMENT = True\n",
    "MIN_DATA_MODE = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "if SHOW_IN_RELEASE:\n",
    "    show_image('Sorry')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "if SHOW_IN_RELEASE:\n",
    "    show_image('Data_Collectors')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if SHOW_IN_RELEASE:\n",
    "    pass\n",
    "    #warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Load the data\n",
    "\n",
    "df_original = read_csv('businesses')\n",
    "\n",
    "if MIN_DATA_MODE:\n",
    "    df_original = train_test_split(df_original, train_size=0.05, random_state=70)[0]\n",
    "\n",
    "df = df_original.copy()\n",
    "\n",
    "# Remove text columns and 'ExpensiveLevel'\n",
    "df.drop([\"Url\", \"Name\", \"ExpensiveLevel\", \"SubCategories\", \"AttributesHas\"], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Split the data to Train and Final Test\n",
    "\n",
    "Y = target = df[\"HasExpensiveLevel\"]\n",
    "X = data = df.drop([\"HasExpensiveLevel\"], axis=1)\n",
    "x_train, x_finale_test, y_train, y_finale_test = train_test_split(X, Y, test_size=0.03, random_state=70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# create Data Frame of the Train Data\n",
    "\n",
    "df = df_train = pd.concat([y_train, x_train], axis=1)\n",
    "df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visuation for undsending the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Config\n",
    "# Config Colors\n",
    "legend_colors = ['tab:blue', 'tab:orange']\n",
    "\n",
    "# Config columns names\n",
    "target_column = \"HasExpensiveLevel\"\n",
    "target_column_label = \"Is Expensive\"\n",
    "target_column_label_true = \"Is Expensive\"\n",
    "target_column_label_false = \"Is not Expensive\"\n",
    "\n",
    "prime_flag_columns = [\n",
    "    'Claimed', 'HasWebsite'\n",
    "]\n",
    "\n",
    "prime_countable_columns = [\n",
    "    'Stars',\n",
    "    'SubCategoriesCount', 'AttributesCount',\n",
    "    'QuestionsCount', 'WeeklyBreaks', 'WeeklyDays'\n",
    "]\n",
    "prime_non_countable_columns = [\n",
    "     'Reviews', 'Photos',\n",
    "    'WeeklyHours'\n",
    "]\n",
    "\n",
    "prime_columns = prime_flag_columns + prime_countable_columns + prime_non_countable_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Describe\n",
    "df[[target_column] + prime_columns].describe()\n",
    "\n",
    "# The data is balanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visuation functions for columns\n",
    "\n",
    "def disply_count_of_flag_column(column_name: str, column_label: str, true_label: str, false_label: str, labels: list):\n",
    "    global legend_colors, df, target_column\n",
    "    \n",
    "    df_sp = df[[target_column, column_name]]\n",
    "    \n",
    "    count_df = df_sp.groupby([column_name]).count()\n",
    "    \n",
    "    count_true_has = df_sp[df_sp[column_name] == 1][target_column].sum()\n",
    "    count_true_not_has = df_sp[df_sp[column_name] == 1][target_column].count() - count_true_has\n",
    "    \n",
    "    count_false_has = df_sp[df_sp[column_name] == 0][target_column].sum()\n",
    "    count_false_not_has = df_sp[df_sp[column_name] == 0][target_column].count() - count_false_has\n",
    "    \n",
    "    # Main elements    \n",
    "    fig = plt.figure(figsize = [16, 8])\n",
    "    \n",
    "    fig.suptitle(column_label)\n",
    "    \n",
    "    ax_graf =  fig.add_subplot(1, 3, 1)\n",
    "    ax_true =  fig.add_subplot(1, 3, 2)\n",
    "    ax_false = fig.add_subplot(1, 3, 3) \n",
    "        \n",
    "    # Graf\n",
    "    plt.sca(ax_graf)\n",
    "    ax_graf.bar( [true_label,false_label], count_df[target_column].values)\n",
    "    plt.xlabel(true_label)\n",
    "    plt.ylabel(\"Count\")\n",
    "    \n",
    "    # Pies\n",
    "    plt.sca(ax_true)\n",
    "    plt.title(true_label)\n",
    "    \n",
    "    ax_true.pie([count_true_has, count_true_not_has],\n",
    "                radius=4,\n",
    "                center=(4, 4),\n",
    "                startangle=90,\n",
    "                autopct='%1.0f%%',\n",
    "                colors=legend_colors)\n",
    "    \n",
    "    ax_true.set(xlim=(0, 8), ylim=(0, 8))\n",
    "        \n",
    "    plt.sca(ax_false)\n",
    "    plt.title(false_label)\n",
    "    ax_false.pie([count_false_has, count_false_not_has],\n",
    "                radius=4,\n",
    "                center=(4, 4),\n",
    "                startangle=90,\n",
    "                autopct='%1.0f%%',\n",
    "                colors=legend_colors)\n",
    "    \n",
    "    ax_false.set(xlim=(0, 8), ylim=(0, 8))\n",
    "    \n",
    "    # show        \n",
    "    handles = []\n",
    "    for i in range(len(labels)):\n",
    "        handles.append(matplotlib.patches.Patch(label=labels[i], color=legend_colors[i]))\n",
    "\n",
    "    fig.legend(handles=handles, loc =\"lower right\")\n",
    "    \n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def disply_atter_per_column(inedexs: list, values: list, columns_label: list, min_value: float, max_value: float):\n",
    "    global legend_colors, target_column, target_column_label\n",
    "    \n",
    "    # Main elements    \n",
    "    fig = plt.figure(figsize = [16, 8])\n",
    "        \n",
    "    for i in range(len(values)):        \n",
    "        value = values[i]\n",
    "        if value is not None:\n",
    "            index = indexs[i]\n",
    "            label = columns_label[i]\n",
    "            \n",
    "            # Graf\n",
    "            ax_graf =  fig.add_subplot(1, len(values), i+1)\n",
    "            \n",
    "            plt.sca(ax_graf)\n",
    "            plt.plot(index, value)\n",
    "            plt.xlabel(label)\n",
    "            plt.ylabel(target_column_label)\n",
    "            plt.ylim(min_value, max_value)\n",
    "            \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def disply_mluti_bars(inedexs: list, values: list, indexs_label, values_label, elements_in_line: int):\n",
    "    global legend_colors\n",
    "    \n",
    "    values += np.full(elements_in_line-len(values)%elements_in_line, None).tolist()\n",
    "    inedexs += np.full(elements_in_line-len(values)%elements_in_line, None).tolist()\n",
    "    \n",
    "    h = int(len(values) / elements_in_line)\n",
    "    \n",
    "    # Main elements \n",
    "    fig = plt.figure(figsize = [16, h * 8])\n",
    "    \n",
    "    gs = fig.add_gridspec(h, elements_in_line)\n",
    "    \n",
    "    line = 0\n",
    "    while len(values) > 0:\n",
    "        now_values = values[:elements_in_line]\n",
    "        now_inedexs = inedexs[:elements_in_line]\n",
    "                \n",
    "        for i in range(elements_in_line):        \n",
    "            value = now_values[i]\n",
    "            if value is not None:\n",
    "                index = now_inedexs[i]\n",
    "                value = now_values[i]\n",
    "            \n",
    "                index_label = indexs_label\n",
    "                value_label = values_label\n",
    "                if type(indexs_label) == list:\n",
    "                    index_label = indexs_label[i]\n",
    "            \n",
    "                if type(values_label) == list:\n",
    "                    value_label = values_label[i]\n",
    "            \n",
    "                # Graf\n",
    "                ax_graf = fig.add_subplot(gs[line, i])\n",
    "        \n",
    "                plt.sca(ax_graf)\n",
    "                plt.bar(index, value)\n",
    "                plt.xlabel(index_label)\n",
    "                plt.ylabel(value_label)\n",
    "                \n",
    "        values = values[elements_in_line:]\n",
    "        inedexs = inedexs[elements_in_line:]\n",
    "        \n",
    "        if type(indexs_label) == list:\n",
    "            indexs_label = indexs_label[elements_in_line:]\n",
    "            \n",
    "        if type(values_label) == list:\n",
    "            values_label = values_label[elements_in_line:]\n",
    "        \n",
    "        line += 1\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Shows the average of \"Has Expensive Level\" for every column by value\n",
    "# Average of \"Has Expensive Level\" symbolizes how likely it is to have expensive level\n",
    "\n",
    "if SHOW_IN_RELEASE:\n",
    "    \n",
    "    printed_columns = prime_countable_columns\n",
    "    atter_name = 'mean'\n",
    "    \n",
    "    elements_in_line = 3\n",
    "    printed_columns += np.full(elements_in_line-len(printed_columns)%elements_in_line, None).tolist()\n",
    "    while len(printed_columns) > 0:\n",
    "        now_columns = printed_columns[:elements_in_line]\n",
    "        indexs = []\n",
    "        values = []\n",
    "        for column in now_columns:\n",
    "            if column is None:\n",
    "                indexs += [None]\n",
    "                values += [None]\n",
    "            else:\n",
    "                atter_df = df[[target_column, column]].groupby([column])\n",
    "                atter_df = getattr(atter_df, atter_name)()\n",
    "            \n",
    "                indexs += [atter_df.index]\n",
    "                values += [atter_df[target_column].values]            \n",
    "        \n",
    "        disply_atter_per_column(indexs, values, printed_columns[:elements_in_line], 0.0, 1.0)\n",
    "        printed_columns = printed_columns[elements_in_line:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## calculates the probability based on sections\n",
    "\n",
    "if SHOW_IN_RELEASE:\n",
    "    \n",
    "    sections=20\n",
    "    atter_name = 'mean'\n",
    "    elements_in_line = 2\n",
    "    printed_columns = prime_non_countable_columns\n",
    "    \n",
    "    printed_columns += np.full(elements_in_line-len(printed_columns)%elements_in_line, None).tolist()\n",
    "    while len(printed_columns) > 0:\n",
    "        now_columns = printed_columns[:elements_in_line]\n",
    "        indexs = []\n",
    "        values = []\n",
    "        for column in now_columns:\n",
    "            if column is None:\n",
    "                indexs += [None]\n",
    "                values += [None]\n",
    "            else:\n",
    "                new_df = df[[target_column, column]].sort_values(column)\n",
    "                length = len(new_df)\n",
    "                new_df[\"Sections\"] = df.index//(length//sections)\n",
    "                section_name = range(0,100,100//sections)\n",
    "                atter_df = new_df[[target_column, \"Sections\"]].groupby([\"Sections\"])\n",
    "                atter_df = getattr(atter_df, atter_name)()\n",
    "            \n",
    "                indexs += [atter_df.index]\n",
    "                values += [atter_df[target_column].values]            \n",
    "        \n",
    "        disply_atter_per_column(indexs, values, printed_columns[:elements_in_line], 0.0, 1.0)\n",
    "        printed_columns = printed_columns[elements_in_line:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shows Claimed\n",
    "\n",
    "if SHOW_IN_RELEASE: \n",
    "    disply_count_of_flag_column('Claimed', 'Claimed', 'Claimed', 'Unclaimed',\n",
    "                                [target_column_label_true, target_column_label_false])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Has Website\n",
    "\n",
    "if SHOW_IN_RELEASE:\n",
    "    disply_count_of_flag_column('HasWebsite', 'Has Website', 'Have', 'Not Have',\n",
    "                                [target_column_label_true, target_column_label_false])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Shows how much data we have for each value in each feature\n",
    "\n",
    "if SHOW_IN_RELEASE:\n",
    "    \n",
    "    printed_columns = prime_countable_columns  \n",
    "    elements_in_line = 3\n",
    "    indexs = []\n",
    "    values = []\n",
    "    for column in printed_columns:\n",
    "        if column is not None:\n",
    "            count_df = df[[target_column, column]].groupby([column]).count()\n",
    "            \n",
    "            indexs += [count_df.index]\n",
    "            values += [count_df[target_column].values.tolist()]            \n",
    "    \n",
    "    disply_mluti_bars(indexs, values, printed_columns, 'Count', elements_in_line)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if SHOW_IN_RELEASE:\n",
    "    \n",
    "    printed_columns = prime_non_countable_columns    \n",
    "    elements_in_line = 3\n",
    "    printed_columns += np.full(elements_in_line-len(printed_columns)%elements_in_line, None).tolist()\n",
    "    while len(printed_columns) > 0:\n",
    "        now_columns = printed_columns[:elements_in_line]\n",
    "        indexs = []\n",
    "        values = []\n",
    "        for column in now_columns:\n",
    "            if column is None:\n",
    "                indexs += [None]\n",
    "                values += [None]\n",
    "            else:\n",
    "                count_df = df[[target_column, column]].groupby([column]).count()\n",
    "            \n",
    "                indexs += [count_df.index]\n",
    "                values += [count_df[target_column].values.tolist()]            \n",
    "\n",
    "        disply_mluti_bars(indexs, values, printed_columns[:elements_in_line], 'Count', elements_in_line)\n",
    "        printed_columns = printed_columns[elements_in_line:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Shows how much features we lose if we decide to limit the amount of instances a category should have to appear\n",
    "\n",
    "if SHOW_IN_RELEASE:\n",
    "    column_values = df.columns.map(lambda x: x.startswith(\"Cat_\"))\n",
    "    cat_df = df.loc[:, column_values]\n",
    "    categ = cat_df.sum().sort_values()\n",
    "    limits = range(50)\n",
    "    remainders = []\n",
    "    for limit in limits:\n",
    "        remainders += [(categ.values<limit).sum()]\n",
    "    fig= plt.figure()\n",
    "    ax_graph= fig.add_subplot(1,1,1)\n",
    "    ax_graph= plt.step(remainders,limits)\n",
    "    for i in range(0,50,5):\n",
    "        plt.plot([0,300],[i,i],linestyle= \":\" )\n",
    "    plt.ylabel(\"the cutoff\")\n",
    "    plt.xlabel(\"categories we lose\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shows us how much categories we have for different probabilities\n",
    "# This is only for lior\n",
    "\n",
    "if SHOW_IN_RELEASE:\n",
    "    sub_categories = filter(lambda x: x.startswith(\"Cat_\"),df.columns)\n",
    "    x0 = np.arange(0,1.05,0.05)\n",
    "    y0 = np.zeros(21)\n",
    "    x1 = np.arange(0,1.05,0.05)\n",
    "    y1 = np.zeros(21)\n",
    "    for category in sub_categories:\n",
    "        mean_df = df[[target_column, category]].groupby([category]).mean()\n",
    "        y0[(int)((mean_df.loc[0.0,target_column]*20).round())] += 1\n",
    "        if (1.0 in mean_df.index):\n",
    "            y1[(int)((mean_df.loc[1.0,target_column]*20).round())] += 1\n",
    "    fig = plt.figure()\n",
    "    ax0_graph = fig.add_subplot(2,1,1)\n",
    "    plt.plot(x0,y0)\n",
    "    plt.xlabel(\"probability of is expensive given not in category\")\n",
    "    plt.ylabel(\"amount of categories\")\n",
    "    ax1_graph = fig.add_subplot(2,1,2)\n",
    "    ax1_graph = plt.plot(x1,y1)\n",
    "    plt.xlabel(\"probability of is expensive given in category\")\n",
    "    plt.ylabel(\"amount of categories\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## create collumns which generally represents a bunch of other collumns based on their relative probability\n",
    "class create_general_collumns:\n",
    "    \n",
    "    def __init__(self, starter, collumns_number):\n",
    "        self.collumn_map = np.empty(collumns_number+1, dtype= object)\n",
    "        self.starter = starter\n",
    "        self.starts = lambda x:x.startswith(starter)\n",
    "        self.collumns_number = collumns_number\n",
    "        \n",
    "        \n",
    "    def fit(self, df_create: pd.DataFrame):\n",
    "        sub_categories = filter(self.starts, df_create.columns)\n",
    "        \n",
    "        for i in range(self.collumn_map.shape[0]):\n",
    "            self.collumn_map[i] = []\n",
    "        \n",
    "        for category in sub_categories:\n",
    "            mean_df = df[[target_column, category]].groupby([category]).mean()\n",
    "            if (1.0 in mean_df.index):\n",
    "                self.collumn_map[(int)((mean_df.loc[1.0, target_column]*self.collumns_number).round())] += [category]\n",
    "    \n",
    "    \n",
    "    def transform(self, df_create:pd.DataFrame):\n",
    "        df_copy = df_create.copy()\n",
    "        \n",
    "        index=0\n",
    "        for category_class in self.collumn_map:\n",
    "            df_copy[\"general\" + self.starter + str(index)] = df_copy[category_class].sum(axis=1)\n",
    "            index += 1\n",
    "        return df_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time enums\n",
    "\n",
    "week_days = {\n",
    "    \"1\": \"Sunday\",\n",
    "    \"2\":\"Monday\",\n",
    "    \"3\":\"Tuesday\",\n",
    "    \"4\":\"Wednesday\",\n",
    "    \"5\": \"Thursday\",\n",
    "    \"6\":\"Friday\",\n",
    "    \"7\":\"Saturday\"\n",
    "}\n",
    "\n",
    "time_open_select = [\n",
    "    '12:00 AM', '12:30 AM',\n",
    "    '1:00 AM', '1:30 AM',\n",
    "    '2:00 AM', '2:30 AM',\n",
    "    '3:00 AM', '3:30 AM',\n",
    "    '4:00 AM', '4:30 AM',\n",
    "    '5:00 AM', '5:30 AM',\n",
    "    '6:00 AM', '6:30 AM',\n",
    "    '7:00 AM', '7:30 AM',\n",
    "    '8:00 AM', '8:30 AM',\n",
    "    '9:00 AM', '9:30 AM',\n",
    "    '10:00 AM', '10:30 AM',\n",
    "    '11:00 AM', '11:30 AM',\n",
    "    '12:00 PM', '12:30 PM',\n",
    "    '1:00 PM', '1:30 PM',\n",
    "    '2:00 PM', '2:30 PM',\n",
    "    '3:00 PM', '3:30 PM',\n",
    "    '4:00 PM', '4:30 PM',\n",
    "    '5:00 PM', '5:30 PM',\n",
    "    '6:00 PM', '6:30 PM',\n",
    "    '7:00 PM', '7:30 PM',\n",
    "    '8:00 PM', '8:30 PM',\n",
    "    '9:00 PM', '9:30 PM',\n",
    "    '10:00 PM', '10:30 PM',\n",
    "    '11:00 PM', '11:30 PM',\n",
    "    ]\n",
    "\n",
    "time_end_select = [\n",
    "    '12:00 AM', '12:30 AM',\n",
    "    '1:00 AM', '1:30 AM',\n",
    "    '2:00 AM', '2:30 AM',\n",
    "    '3:00 AM', '3:30 AM',\n",
    "    '4:00 AM', '4:30 AM',\n",
    "    '5:00 AM', '5:30 AM',\n",
    "    '6:00 AM', '6:30 AM',\n",
    "    '7:00 AM', '7:30 AM',\n",
    "    '8:00 AM', '8:30 AM',\n",
    "    '9:00 AM', '9:30 AM',\n",
    "    '10:00 AM', '10:30 AM',\n",
    "    '11:00 AM', '11:30 AM',\n",
    "    '12:00 PM', '12:30 PM',\n",
    "    '1:00 PM', '1:30 PM',\n",
    "    '2:00 PM', '2:30 PM',\n",
    "    '3:00 PM', '3:30 PM',\n",
    "    '4:00 PM', '4:30 PM',\n",
    "    '5:00 PM', '5:30 PM',\n",
    "    '6:00 PM', '6:30 PM',\n",
    "    '7:00 PM', '7:30 PM',\n",
    "    '8:00 PM', '8:30 PM',\n",
    "    '9:00 PM', '9:30 PM',\n",
    "    '10:00 PM', '10:30 PM',\n",
    "    '11:00 PM', '11:30 PM',\n",
    "    '12:00 AM ', '12:30 AM',\n",
    "    '1:00 AM ', '1:30 AM ',\n",
    "    '2:00 AM ', '2:30 AM ',\n",
    "    '3:00 AM ', '3:30 AM ',\n",
    "    '4:00 AM ', '4:30 AM ',\n",
    "    '5:00 AM ', '5:30 AM ',\n",
    "    '6:00 AM ', '6:30 AM ',\n",
    "    ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the opening hour ped day\n",
    "\n",
    "if SHOW_IN_RELEASE:    \n",
    "    fig = plt.figure(figsize= (16, 8))\n",
    "    \n",
    "    ax = fig.add_subplot(1, 1, 1)\n",
    "    plt.sca(ax)\n",
    "    \n",
    "    plt.ylabel(\"is expensive\")\n",
    "    plt.xlabel(\"Opening Hour\")\n",
    "    \n",
    "    for i in range(7):\n",
    "        mean_df = df[[\"OpenHour\"+str(i+1), target_column]].groupby([\"OpenHour\"+str(i+1)]).mean()\n",
    "        plt.plot(mean_df.index, mean_df.values, label = week_days[str(i+1)])\n",
    "    \n",
    "    ax.set_xticks(range(0,48,6))\n",
    "    ax.set_xticklabels(map(lambda x:time_open_select[int(x)], range(0,48,6)))\n",
    "    \n",
    "    plt.ylim(-0.1, 1.1)\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the Daily Hours per day\n",
    "\n",
    "if SHOW_IN_RELEASE:    \n",
    "    fig = plt.figure(figsize= (16, 8))\n",
    "    \n",
    "    ax = fig.add_subplot(1, 1, 1)\n",
    "    plt.sca(ax)\n",
    "    \n",
    "    plt.ylabel(\"is expensive\")\n",
    "    plt.xlabel(\"Daily Hours\")\n",
    "    \n",
    "    for i in range(7):\n",
    "        mean_df = df[[\"CountHour\"+str(i+1),target_column]].groupby([\"CountHour\"+str(i+1)]).mean()\n",
    "        plt.plot(mean_df.index,mean_df.values,label = week_days[str(i+1)])\n",
    "\n",
    "    plt.ylim(-0.1, 1.1)\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the ending hour ped day\n",
    "\n",
    "if SHOW_IN_RELEASE:    \n",
    "    fig = plt.figure(figsize= (16, 8 * 4))\n",
    "    \n",
    "    for i in range(7):\n",
    "        ax_end=fig.add_subplot(5, 2, 1+i)\n",
    "        plt.sca(ax_end)\n",
    "        plt.ylabel(\"is expensive\")\n",
    "        plt.xlabel(\"Ending Hour\")\n",
    "        ax_end.set_title(week_days[str(i+1)])\n",
    "        mean_df = df[[\"EndHour\"+str(i+1),target_column]].groupby([\"EndHour\"+str(i+1)]).mean()\n",
    "        plt.plot(mean_df.index,mean_df.values)\n",
    "        ax_end.set_xticks(range(0,61,6))\n",
    "        ax_end.set_xticklabels(map(lambda x:time_end_select[int(x)], range(0,61,6)))\n",
    "                    \n",
    "        plt.ylim(-0.1, 1.1)\n",
    "    \n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Split the tain data,\n",
    "\n",
    "x_sub_train, x_sub_test, y_sub_train, y_sub_test = train_test_split(x_train, y_train, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Create a Simple model base KNN\n",
    "\n",
    "if SHOW_IN_RELEASE:\n",
    "    knn = KNeighborsClassifier()\n",
    "\n",
    "    knn.fit(x_sub_train, y_sub_train)\n",
    "\n",
    "    score = knn.score(x_sub_test, y_sub_test)\n",
    "    print(\"Score: \", score)\n",
    "\n",
    "# Score:  0.78"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Create modal zero (Dummy Modal)\n",
    "\n",
    "if SHOW_IN_RELEASE:\n",
    "    dummy_modal = DummyClassifier()\n",
    "\n",
    "    dummy_modal.fit(x_sub_train, y_sub_train)\n",
    "\n",
    "    score = dummy_modal.score(x_sub_test, y_sub_test)\n",
    "    print(\"Dummy Modal Score: \", score)\n",
    "\n",
    "# Dummy Modal Score:  0.65"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df_models = pd.DataFrame({\n",
    "    'Name': [],\n",
    "    'Score': [],\n",
    "    'Best Params': []\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEFAULT_CV = 5\n",
    "DEFAULT_RANDOM_STATE = 70"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creates models for testing\n",
    "# old parameter: scale_me\n",
    "# models: list of model_param (dict)\n",
    "# model_param paraments:\n",
    "#   name : name the new model\n",
    "#   model: model class from sklearn\n",
    "#   params: param_grid for Grid Search\n",
    "# model_param optional paraments:\n",
    "#   disable_random_state: remove random_state arg\n",
    "#   cv: cv for Grid Search\n",
    "#   to_scale: flag if to scale the data\n",
    "#   preprocessor: preprocessor function\n",
    "#   selected: flag if to add to return arr\n",
    "def try_multi_models(models, scale_me: bool):\n",
    "    global x_sub_train, y_sub_train, x_sub_test, y_sub_test\n",
    "    global df_models\n",
    "    \n",
    "    ret = []\n",
    "    \n",
    "    df_models_add = pd.DataFrame({\n",
    "        'Name': np.full(len(models), None),\n",
    "        'Score': np.full(len(models), None),\n",
    "        'Best Params': np.full(len(models), None),  \n",
    "    })\n",
    "        \n",
    "    i = 0\n",
    "    for model_params in models:\n",
    "        name = model_params['name']\n",
    "        df_models_add.at[i, 'Name'] = name\n",
    "        print('Work on ', name)\n",
    "        try:\n",
    "            model_class = model_params['model']\n",
    "            if ('disable_random_state' in model_params and model_params['disable_random_state']):\n",
    "                model = model_class()\n",
    "            else:\n",
    "                model = model_class(random_state=DEFAULT_RANDOM_STATE)\n",
    "                \n",
    "            if 'cv' in model_params:\n",
    "                cv = model_params['cv']\n",
    "            else:\n",
    "                cv = DEFAULT_CV\n",
    "            \n",
    "            to_scale = scale_me\n",
    "            if 'to_scale' in model_params:\n",
    "                to_scale = model_params['to_scale']\n",
    "            \n",
    "            x_sub_train_now = x_sub_train\n",
    "            y_sub_train_now = y_sub_train\n",
    "            x_sub_test_now = x_sub_test\n",
    "            y_sub_test_now = y_sub_test\n",
    "    \n",
    "            if to_scale:\n",
    "                scaler = StandardScaler()\n",
    "                x_sub_train_now = scaler.fit_transform(X=x_sub_train_now)\n",
    "                x_sub_test_now = scaler.transform(x_sub_test_now)\n",
    "            \n",
    "            if 'preprocessor' in model_params:\n",
    "                preprocessor = model_params['preprocessor']        \n",
    "                \n",
    "                x_sub_train_now, y_sub_train_now, x_sub_test_now, y_sub_test_now = preprocessor(x_sub_train_now, y_sub_train_now, x_sub_test_now, y_sub_test_now)\n",
    "\n",
    "            \n",
    "            param_grid = model_params['params']\n",
    "            \n",
    "            if cv is None:\n",
    "                grid_search = GridSearchCV(estimator=model, param_grid=param_grid)\n",
    "            else:\n",
    "                grid_search = GridSearchCV(estimator=model, param_grid=param_grid, cv=cv)\n",
    "            \n",
    "            print('Fit ', name)\n",
    "            grid_search.fit(x_sub_train_now, y_sub_train_now)\n",
    "            \n",
    "            score = grid_search.score(x_sub_test_now, y_sub_test_now)\n",
    "            print(name, \" Score: \", score)\n",
    "            \n",
    "            df_models_add.at[i, 'Score'] = score\n",
    "            df_models_add.at[i, 'Best Params'] = json.dumps(grid_search.best_params_)\n",
    "            \n",
    "            if 'selected' in model_params and model_params['selected']:\n",
    "                res_as_df = pd.concat([pd.DataFrame(grid_search.cv_results_[\"params\"]), pd.DataFrame(grid_search.cv_results_[\"mean_test_score\"], columns=[\"Accuracy\"])], axis=1)\n",
    "                res_as_df.sort_values('Accuracy', ascending=False, inplace=True)\n",
    "                ret.append(res_as_df)\n",
    "            \n",
    "        except Exception as ex:\n",
    "            print(name, \" Failed!\", ex)\n",
    "        \n",
    "        i += 1\n",
    "    \n",
    "    df_models = pd.concat([df_models, df_models_add])\n",
    "    df_models.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First tring\n",
    "\n",
    "if SHOW_IN_RELEASE:\n",
    "    models = [\n",
    "        \n",
    "        {\n",
    "            'name': 'KNeighborsClassifier',\n",
    "            'model': KNeighborsClassifier,\n",
    "            'params': {},\n",
    "            'disable_random_state': True\n",
    "        }, {\n",
    "            'name': 'LogisticRegression',\n",
    "            'model': LogisticRegression,\n",
    "            'params': {\n",
    "                'max_iter': [100, 200]\n",
    "            }\n",
    "        }, {\n",
    "            'name': 'Lasso',\n",
    "            'model': Lasso,\n",
    "            'params': {}\n",
    "        }, {\n",
    "#            'name': 'SVC',\n",
    "#            'model': SVC,\n",
    "#            'params': {},\n",
    "#            'disable_random_state': True\n",
    "#        }, {\n",
    "            'name': 'LinearSVC',\n",
    "            'model': LinearSVC,\n",
    "            'params': {}\n",
    "        }, {\n",
    "#            'name': 'SVR',\n",
    "#            'model': SVR,\n",
    "#            'params': {},\n",
    "#            'disable_random_state': True\n",
    "#        }, {\n",
    "            'name': 'RandomForestClassifier',\n",
    "            'model': RandomForestClassifier,\n",
    "            'params': {}\n",
    "        }\n",
    "    ]\n",
    "\n",
    "    try_multi_models(models, False)\n",
    "\n",
    "# RandomForestClassifier Score:  0.8541162227602905\n",
    "# LinearSVC              Score:  0.8243038740920097\n",
    "# LogisticRegression     Score:  0.8193099273607748\n",
    "# KNeighborsClassifier   Score:  0.7860169491525424\n",
    "# SVR                    Score:  0.3687542760469187\n",
    "# Lasso                  Score:  0.10050948422148354"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Tring other models\n",
    "\n",
    "if SHOW_IN_RELEASE:\n",
    "    models = [\n",
    "        {\n",
    "            'name': 'RandomForestRegressor',\n",
    "            'model': RandomForestRegressor,\n",
    "            'params': {}\n",
    "        }\n",
    "    ]\n",
    "\n",
    "    try_multi_models(models, False)\n",
    "# RandomForestRegressor  Score:  0.5371579181722024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_models.sort_values('Score', ascending=False, inplace=True)\n",
    "df_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The bast score comes form Random Forest Classifier\n",
    "# https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Learning about VotingClassifier\n",
    "\n",
    "if SHOW_IN_RELEASE:\n",
    "    vs = VotingClassifier(estimators=[\n",
    "        ('RandomForestClassifier', RandomForestClassifier()),\n",
    "        ('LogisticRegression', LogisticRegression())\n",
    "    ])\n",
    "\n",
    "    vs.fit(x_sub_train, y_sub_train)\n",
    "\n",
    "    score = vs.score(x_sub_test, y_sub_test)\n",
    "    print(\"Voting Classifier Score: \", score)\n",
    "\n",
    "# Voting Classifier Score:  0.8221852300242131\n",
    "\n",
    "# Not good, Random Forest gives 0.85 alone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Tring other models\n",
    "\n",
    "ret = ['None']\n",
    "if SHOW_IN_RELEASE:\n",
    "    models = [\n",
    "        {\n",
    "            'name': 'RandomForestClassifier V2',\n",
    "            'model': RandomForestClassifier,\n",
    "            'params': {\n",
    "                'n_estimators': range(100, 201, 100)\n",
    "            }\n",
    "        }\n",
    "    ]\n",
    "\n",
    "    try_multi_models(models, False)\n",
    "\n",
    "# n_estimators not Change to muth,\n",
    "# 200 estimators is the best\n",
    "\n",
    "ret[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if SHOW_IN_RELEASE:\n",
    "    models = [\n",
    "        {\n",
    "            'name': 'KNeighborsClassifier Scaler',\n",
    "            'model': KNeighborsClassifier,\n",
    "            'params': {},\n",
    "            'disable_random_state': True\n",
    "        }, {\n",
    "            'name': 'LogisticRegression Scaler',\n",
    "            'model': LogisticRegression,\n",
    "            'params': {\n",
    "                'max_iter': [100, 200]\n",
    "            }\n",
    "        }, {\n",
    "            'name': 'LinearSVC Scaler',\n",
    "            'model': LinearSVC,\n",
    "            'params': {}\n",
    "        }, {\n",
    "            'name': 'RandomForestClassifier Scaler',\n",
    "            'model': RandomForestClassifier,\n",
    "            'params': {\n",
    "                'n_estimators': range(100, 851, 50)\n",
    "            },\n",
    "            'selected': True\n",
    "        }\n",
    "    ]\n",
    "\n",
    "    ret = try_multi_models(models, True)\n",
    "\n",
    "# \n",
    "ret[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if SHOW_IN_RELEASE:\n",
    "    models = [\n",
    "        {\n",
    "            'name': 'LogisticRegression Scaler',\n",
    "            'model': LogisticRegression,\n",
    "            'params': {\n",
    "                'max_iter': [100]\n",
    "            }\n",
    "        }, {\n",
    "            'name': 'LinearSVC Scaler',\n",
    "            'model': LinearSVC,\n",
    "            'params': {}\n",
    "        }, {\n",
    "            'name': 'RandomForestClassifier Scaler',\n",
    "            'model': RandomForestClassifier,\n",
    "            'params': {\n",
    "                'n_estimators': [200]\n",
    "            },\n",
    "            'selected': True\n",
    "        }\n",
    "    ]\n",
    "\n",
    "    ret = try_multi_models(models, True)\n",
    "\n",
    "# \n",
    "ret[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_models.sort_values('Score', ascending=False, inplace=True)\n",
    "df_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "version_model = 1\n",
    "\n",
    "def learn_load():\n",
    "    global x_sub_train, x_sub_test, y_sub_train, y_sub_test\n",
    "    x_sub_train, x_sub_test, y_sub_train, y_sub_test = train_test_split(x_train, y_train, random_state=42)\n",
    "\n",
    "def learn_fit():    \n",
    "    global version_model\n",
    "    version_model += 1\n",
    "    models = [\n",
    "        {\n",
    "            'name': 'RandomForestClassifier ' + str(version_model),\n",
    "            'model': RandomForestClassifier,\n",
    "            'params': {\n",
    "                'n_estimators': [200]\n",
    "            },\n",
    "            'selected': True\n",
    "        }, {\n",
    "            'name': 'LogisticRegression ' + str(version_model),\n",
    "            'model': LogisticRegression,\n",
    "            'params': {\n",
    "                'max_iter': [100]\n",
    "            },\n",
    "            'to_scale': True\n",
    "        }, {\n",
    "            'name': 'LinearSVC ' + str(version_model),\n",
    "            'model': LinearSVC,\n",
    "            'params': {},\n",
    "            'to_scale': True\n",
    "        }\n",
    "    ]\n",
    "\n",
    "    return try_multi_models(models, False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if SHOW_IN_RELEASE:\n",
    "    learn_load()\n",
    "\n",
    "    create_coll = create_general_collumns(\"Cat\", 15)\n",
    "    create_coll.fit(x_sub_train)\n",
    "    x_sub_train = create_coll.transform(x_sub_train)\n",
    "    x_sub_test = create_coll.transform(x_sub_test)\n",
    "\n",
    "    learn_fit()\n",
    "    df_models.sort_values('Score', ascending=False, inplace=True)\n",
    "\n",
    "df_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_models.sort_values('Score', ascending=False, inplace=True)\n",
    "df_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if SHOW_IN_RELEASE:\n",
    "    learn_load()\n",
    "\n",
    "    def check(x):\n",
    "        if x == 'HasExpensiveLevel':\n",
    "            return False\n",
    "\n",
    "        if x.startswith(\"Cat_\"):\n",
    "            return False\n",
    "        if x.startswith(\"ExtraAt_\"):\n",
    "            return False\n",
    "        if x.startswith(\"At_\"):\n",
    "            return False\n",
    "\n",
    "        return True\n",
    "\n",
    "    fi = list(filter(check, df.columns))\n",
    "\n",
    "    x_sub_train = x_sub_train[fi]\n",
    "    x_sub_test = x_sub_test[fi]\n",
    "\n",
    "    learn_fit()\n",
    "    df_models.sort_values('Score', ascending=False, inplace=True)\n",
    "\n",
    "df_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if SHOW_IN_RELEASE:\n",
    "    learn_load()\n",
    "\n",
    "    def check(x):\n",
    "        if x == 'HasExpensiveLevel':\n",
    "            return False\n",
    "\n",
    "        if x.startswith(\"Cat_\"):\n",
    "            return False\n",
    "        if x.startswith(\"ExtraAt_\"):\n",
    "            return False\n",
    "\n",
    "        return True\n",
    "\n",
    "    fi = list(filter(check, df.columns))\n",
    "\n",
    "    x_sub_train = x_sub_train[fi]\n",
    "    x_sub_test = x_sub_test[fi]\n",
    "\n",
    "    learn_fit()\n",
    "    df_models.sort_values('Score', ascending=False, inplace=True)\n",
    "\n",
    "df_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if SHOW_IN_RELEASE:\n",
    "    def learn_fit():    \n",
    "        global version_model\n",
    "        version_model += 1\n",
    "        models = [\n",
    "            {\n",
    "                'name': 'LinearSVC ' + str(version_model),\n",
    "                'model': LinearSVC,\n",
    "                'params': {\n",
    "                    'max_iter': list(range(800, 2001, 100))\n",
    "                },\n",
    "                'to_scale': True,\n",
    "                'cv': 5\n",
    "            }\n",
    "        ]\n",
    "\n",
    "        return try_multi_models(models, False)\n",
    "\n",
    "    learn_load()\n",
    "\n",
    "    def check(x):\n",
    "        if x == 'HasExpensiveLevel':\n",
    "            return False\n",
    "\n",
    "        if x.startswith(\"Cat_\"):\n",
    "            return False\n",
    "        if x.startswith(\"ExtraAt_\"):\n",
    "            return False\n",
    "\n",
    "        return True\n",
    "\n",
    "    fi = list(filter(check, df.columns))\n",
    "\n",
    "    x_sub_train = x_sub_train[fi]\n",
    "    x_sub_test = x_sub_test[fi]\n",
    "\n",
    "    learn_fit()\n",
    "    df_models.sort_values('Score', ascending=False, inplace=True)\n",
    "\n",
    "df_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if SHOW_IN_RELEASE:\n",
    "    def learn_fit():    \n",
    "        global version_model\n",
    "        version_model += 1\n",
    "        models = [\n",
    "            {\n",
    "                'name': 'RandomForestClassifier ' + str(version_model),\n",
    "                'model': RandomForestClassifier,\n",
    "                'params': {\n",
    "                    'n_estimators': [200]\n",
    "                },\n",
    "                'preprocessor': pre_RandomForest\n",
    "            }, {\n",
    "                'name': 'LogisticRegression ' + str(version_model),\n",
    "                'model': LogisticRegression,\n",
    "                'params': {\n",
    "                    'max_iter': [100, 200]\n",
    "                },\n",
    "                'preprocessor': pre_LogisticRegression\n",
    "            }, {\n",
    "                'name': 'LinearSVC ' + str(version_model),\n",
    "                'model': LinearSVC,\n",
    "                'params': {\n",
    "                    'max_iter': [800]\n",
    "                },\n",
    "                'cv': 5,\n",
    "                'preprocessor': pre_LinearSVC\n",
    "            }\n",
    "        ]\n",
    "\n",
    "        return try_multi_models(models, False)\n",
    "\n",
    "    learn_load()\n",
    "\n",
    "    def check(x):\n",
    "        if x == 'HasExpensiveLevel':\n",
    "            return False\n",
    "\n",
    "        if x.startswith(\"Cat_\"):\n",
    "            return False\n",
    "        if x.startswith(\"ExtraAt_\"):\n",
    "            return False\n",
    "\n",
    "        return True\n",
    "\n",
    "    def pre_RandomForest(x_sub_train, y_sub_train, x_sub_test, y_sub_test):\n",
    "        fi = list(filter(check, df.columns))\n",
    "        x_sub_train = x_sub_train[fi]\n",
    "        x_sub_test = x_sub_test[fi]\n",
    "\n",
    "        return [x_sub_train, y_sub_train, x_sub_test, y_sub_test]\n",
    "\n",
    "    def pre_LogisticRegression(x_sub_train, y_sub_train, x_sub_test, y_sub_test):\n",
    "\n",
    "        scaler = StandardScaler()\n",
    "        x_sub_train = scaler.fit_transform(X=x_sub_train)\n",
    "        x_sub_test = scaler.transform(x_sub_test)\n",
    "\n",
    "        return [x_sub_train, y_sub_train, x_sub_test, y_sub_test]\n",
    "\n",
    "    def pre_LinearSVC(x_sub_train, y_sub_train, x_sub_test, y_sub_test):\n",
    "\n",
    "        scaler = StandardScaler()\n",
    "        x_sub_train = scaler.fit_transform(X=x_sub_train)\n",
    "        x_sub_test = scaler.transform(x_sub_test)\n",
    "\n",
    "        return [x_sub_train, y_sub_train, x_sub_test, y_sub_test]\n",
    "\n",
    "    learn_fit()\n",
    "    df_models.sort_values('Score', ascending=False, inplace=True)\n",
    "\n",
    "df_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if SHOW_IN_RELEASE:\n",
    "    def learn_fit():    \n",
    "        global version_model\n",
    "        version_model += 1\n",
    "        models = [\n",
    "            {\n",
    "                'name': 'RandomForestClassifier ' + str(version_model),\n",
    "                'model': RandomForestClassifier,\n",
    "                'params': {\n",
    "                    'n_estimators': [200]\n",
    "                },\n",
    "                'preprocessor': pre_RandomForest\n",
    "            }, {\n",
    "                'name': 'LogisticRegression ' + str(version_model),\n",
    "                'model': LogisticRegression,\n",
    "                'params': {\n",
    "                    'max_iter': [100, 200]\n",
    "                },\n",
    "                'preprocessor': pre_LogisticRegression\n",
    "            }, {\n",
    "                'name': 'LinearSVC ' + str(version_model),\n",
    "                'model': LinearSVC,\n",
    "                'params': {\n",
    "                    'max_iter': [800]\n",
    "                },\n",
    "                'cv': 5,\n",
    "                'preprocessor': pre_LinearSVC\n",
    "            }\n",
    "        ]\n",
    "\n",
    "        return try_multi_models(models, False)\n",
    "\n",
    "    learn_load()\n",
    "\n",
    "    def remove_most_of_collumns(x):\n",
    "        if x == 'HasExpensiveLevel':\n",
    "            return False\n",
    "\n",
    "        if x.startswith(\"Cat_\"):\n",
    "            return False\n",
    "        if x.startswith(\"ExtraAt_\"):\n",
    "            return False\n",
    "\n",
    "        return True\n",
    "\n",
    "    def remove_startswith_collumns(texts: list):\n",
    "        def ret(x):\n",
    "            if x == 'HasExpensiveLevel':\n",
    "                return False\n",
    "\n",
    "            for text in texts:\n",
    "                if x.startswith(text):\n",
    "                    return False\n",
    "\n",
    "            return True\n",
    "        return ret\n",
    "\n",
    "    def pre_RandomForest(x_sub_train, y_sub_train, x_sub_test, y_sub_test):\n",
    "        fi = list(filter(remove_most_of_collumns, df.columns))\n",
    "        x_sub_train = x_sub_train[fi]\n",
    "        x_sub_test = x_sub_test[fi]\n",
    "\n",
    "        return [x_sub_train, y_sub_train, x_sub_test, y_sub_test]\n",
    "\n",
    "    def pre_LogisticRegression(x_sub_train, y_sub_train, x_sub_test, y_sub_test):\n",
    "        create_coll = create_general_collumns(\"Cat\", 15)\n",
    "        create_coll.fit(pd.concat([x_sub_train, y_sub_train], axis=1))\n",
    "\n",
    "        x_sub_train = create_coll.transform(x_sub_train)\n",
    "        x_sub_test = create_coll.transform(x_sub_test)\n",
    "\n",
    "        fi = list(filter(remove_startswith_collumns(['Cat_']), df.columns))\n",
    "        x_sub_train = x_sub_train[fi]\n",
    "        x_sub_test = x_sub_test[fi]\n",
    "\n",
    "        scaler = StandardScaler()\n",
    "        x_sub_train = scaler.fit_transform(X=x_sub_train)\n",
    "        x_sub_test = scaler.transform(x_sub_test)\n",
    "\n",
    "        return [x_sub_train, y_sub_train, x_sub_test, y_sub_test]\n",
    "\n",
    "    def pre_LinearSVC(x_sub_train, y_sub_train, x_sub_test, y_sub_test):\n",
    "        create_coll = create_general_collumns(\"Cat\", 15)\n",
    "        create_coll.fit(pd.concat([x_sub_train, y_sub_train], axis=1))\n",
    "\n",
    "        x_sub_train = create_coll.transform(x_sub_train)\n",
    "        x_sub_test = create_coll.transform(x_sub_test)\n",
    "\n",
    "        fi = list(filter(remove_startswith_collumns(['Cat_']), df.columns))\n",
    "        x_sub_train = x_sub_train[fi]\n",
    "        x_sub_test = x_sub_test[fi]\n",
    "\n",
    "        scaler = StandardScaler()\n",
    "        x_sub_train = scaler.fit_transform(X=x_sub_train)\n",
    "        x_sub_test = scaler.transform(x_sub_test)\n",
    "\n",
    "        return [x_sub_train, y_sub_train, x_sub_test, y_sub_test]\n",
    "\n",
    "    learn_fit()\n",
    "    df_models.sort_values('Score', ascending=False, inplace=True)\n",
    "\n",
    "df_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if SHOW_IN_RELEASE:\n",
    "    def learn_fit():    \n",
    "        global version_model\n",
    "        version_model += 1\n",
    "        models = [\n",
    "            {\n",
    "                'name': 'RandomForestClassifier ' + str(version_model),\n",
    "                'model': RandomForestClassifier,\n",
    "                'params': {\n",
    "                    'n_estimators': [200]\n",
    "                },\n",
    "                'preprocessor': pre_RandomForest\n",
    "            }, {\n",
    "                'name': 'LogisticRegression ' + str(version_model),\n",
    "                'model': LogisticRegression,\n",
    "                'params': {\n",
    "                    'max_iter': [100, 200]\n",
    "                },\n",
    "                'preprocessor': pre_LogisticRegression\n",
    "            }, {\n",
    "                'name': 'LinearSVC ' + str(version_model),\n",
    "                'model': LinearSVC,\n",
    "                'params': {\n",
    "                    'max_iter': [800]\n",
    "                },\n",
    "                'cv': 5,\n",
    "                'preprocessor': pre_LinearSVC\n",
    "            }\n",
    "        ]\n",
    "\n",
    "        return try_multi_models(models, False)\n",
    "\n",
    "    learn_load()\n",
    "\n",
    "    def remove_most_of_collumns(x):\n",
    "        if x == 'HasExpensiveLevel':\n",
    "            return False\n",
    "\n",
    "        if x.startswith(\"Cat_\"):\n",
    "            return False\n",
    "        if x.startswith(\"ExtraAt_\"):\n",
    "            return False\n",
    "\n",
    "        return True\n",
    "\n",
    "    def remove_startswith_collumns(texts: list):\n",
    "        def ret(x):\n",
    "            if x == 'HasExpensiveLevel':\n",
    "                return False\n",
    "\n",
    "            for text in texts:\n",
    "                if x.startswith(text):\n",
    "                    return False\n",
    "\n",
    "            return True\n",
    "        return ret\n",
    "\n",
    "    def pre_RandomForest(x_sub_train, y_sub_train, x_sub_test, y_sub_test):\n",
    "        fi = list(filter(remove_most_of_collumns, df.columns))\n",
    "        x_sub_train = x_sub_train[fi]\n",
    "        x_sub_test = x_sub_test[fi]\n",
    "\n",
    "        return [x_sub_train, y_sub_train, x_sub_test, y_sub_test]\n",
    "\n",
    "    def pre_LogisticRegression(x_sub_train, y_sub_train, x_sub_test, y_sub_test):\n",
    "        create_coll = create_general_collumns(\"ExtraAt_\", 15)\n",
    "        create_coll.fit(pd.concat([x_sub_train, y_sub_train], axis=1))\n",
    "\n",
    "        x_sub_train = create_coll.transform(x_sub_train)\n",
    "        x_sub_test = create_coll.transform(x_sub_test)\n",
    "\n",
    "        fi = list(filter(remove_startswith_collumns(['ExtraAt_']), df.columns))\n",
    "        x_sub_train = x_sub_train[fi]\n",
    "        x_sub_test = x_sub_test[fi]\n",
    "\n",
    "        scaler = StandardScaler()\n",
    "        x_sub_train = scaler.fit_transform(X=x_sub_train)\n",
    "        x_sub_test = scaler.transform(x_sub_test)\n",
    "\n",
    "        return [x_sub_train, y_sub_train, x_sub_test, y_sub_test]\n",
    "\n",
    "    def pre_LinearSVC(x_sub_train, y_sub_train, x_sub_test, y_sub_test):\n",
    "        create_coll = create_general_collumns(\"ExtraAt_\", 15)\n",
    "        create_coll.fit(pd.concat([x_sub_train, y_sub_train], axis=1))\n",
    "\n",
    "        x_sub_train = create_coll.transform(x_sub_train)\n",
    "        x_sub_test = create_coll.transform(x_sub_test)\n",
    "\n",
    "        fi = list(filter(remove_startswith_collumns(['ExtraAt_']), df.columns))\n",
    "        x_sub_train = x_sub_train[fi]\n",
    "        x_sub_test = x_sub_test[fi]\n",
    "\n",
    "        scaler = StandardScaler()\n",
    "        x_sub_train = scaler.fit_transform(X=x_sub_train)\n",
    "        x_sub_test = scaler.transform(x_sub_test)\n",
    "\n",
    "        return [x_sub_train, y_sub_train, x_sub_test, y_sub_test]\n",
    "\n",
    "    learn_fit()\n",
    "    df_models.sort_values('Score', ascending=False, inplace=True)\n",
    "\n",
    "df_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if SHOW_IN_RELEASE:\n",
    "    def create_models(params: list):\n",
    "        models = []\n",
    "\n",
    "        for param in params:\n",
    "            add_models = [\n",
    "                {\n",
    "                    'name': 'LogisticRegression ' + str(version_model) + ' - ' + str(param),\n",
    "                    'model': LogisticRegression,\n",
    "                    'params': {\n",
    "                        'max_iter': [200]\n",
    "                    },\n",
    "                    'preprocessor': create_pre_LogisticRegression(param)\n",
    "                }, {\n",
    "                    'name': 'LinearSVC ' + str(version_model) + ' - ' + str(param),\n",
    "                    'model': LinearSVC,\n",
    "                    'params': {\n",
    "                        'max_iter': [800]\n",
    "                    },\n",
    "                    'cv': 5,\n",
    "                    'preprocessor': create_pre_LinearSVC(param)\n",
    "                }\n",
    "            ]\n",
    "\n",
    "            for model in add_models:\n",
    "                models.append(model)\n",
    "\n",
    "        return models\n",
    "\n",
    "\n",
    "    def learn_fit():    \n",
    "        global version_model\n",
    "        version_model += 1\n",
    "        models = create_models(list(range(10, 31, 3)))\n",
    "        return try_multi_models(models, False)\n",
    "\n",
    "    learn_load()\n",
    "\n",
    "    def remove_most_of_collumns(x):\n",
    "        if x == 'HasExpensiveLevel':\n",
    "            return False\n",
    "\n",
    "        if x.startswith(\"Cat_\"):\n",
    "            return False\n",
    "        if x.startswith(\"ExtraAt_\"):\n",
    "            return False\n",
    "\n",
    "        return True\n",
    "\n",
    "    def remove_startswith_collumns(texts: list):\n",
    "        def ret(x):\n",
    "            if x == 'HasExpensiveLevel':\n",
    "                return False\n",
    "\n",
    "            for text in texts:\n",
    "                if x.startswith(text):\n",
    "                    return False\n",
    "\n",
    "            return True\n",
    "        return ret\n",
    "\n",
    "    def pre_RandomForest(x_sub_train, y_sub_train, x_sub_test, y_sub_test):\n",
    "        fi = list(filter(remove_most_of_collumns, df.columns))\n",
    "        x_sub_train = x_sub_train[fi]\n",
    "        x_sub_test = x_sub_test[fi]\n",
    "\n",
    "        return [x_sub_train, y_sub_train, x_sub_test, y_sub_test]\n",
    "\n",
    "    def create_pre_LogisticRegression(param):\n",
    "        def pre_LogisticRegression(x_sub_train, y_sub_train, x_sub_test, y_sub_test):\n",
    "            create_coll = create_general_collumns(\"ExtraAt_\", param)\n",
    "            create_coll.fit(pd.concat([x_sub_train, y_sub_train], axis=1))\n",
    "\n",
    "            x_sub_train = create_coll.transform(x_sub_train)\n",
    "            x_sub_test = create_coll.transform(x_sub_test)\n",
    "\n",
    "            fi = list(filter(remove_startswith_collumns(['ExtraAt_']), df.columns))\n",
    "            x_sub_train = x_sub_train[fi]\n",
    "            x_sub_test = x_sub_test[fi]\n",
    "\n",
    "            scaler = StandardScaler()\n",
    "            x_sub_train = scaler.fit_transform(X=x_sub_train)\n",
    "            x_sub_test = scaler.transform(x_sub_test)\n",
    "\n",
    "            return [x_sub_train, y_sub_train, x_sub_test, y_sub_test]\n",
    "\n",
    "        return pre_LogisticRegression\n",
    "\n",
    "    def create_pre_LinearSVC(param):\n",
    "        def pre_LinearSVC(x_sub_train, y_sub_train, x_sub_test, y_sub_test):\n",
    "            create_coll = create_general_collumns(\"ExtraAt_\", param)\n",
    "            create_coll.fit(pd.concat([x_sub_train, y_sub_train], axis=1))\n",
    "\n",
    "            x_sub_train = create_coll.transform(x_sub_train)\n",
    "            x_sub_test = create_coll.transform(x_sub_test)\n",
    "\n",
    "            fi = list(filter(remove_startswith_collumns(['ExtraAt_']), df.columns))\n",
    "            x_sub_train = x_sub_train[fi]\n",
    "            x_sub_test = x_sub_test[fi]\n",
    "\n",
    "            scaler = StandardScaler()\n",
    "            x_sub_train = scaler.fit_transform(X=x_sub_train)\n",
    "            x_sub_test = scaler.transform(x_sub_test)\n",
    "\n",
    "            return [x_sub_train, y_sub_train, x_sub_test, y_sub_test]\n",
    "        return pre_LinearSVC\n",
    "\n",
    "    learn_fit()\n",
    "    df_models.sort_values('Score', ascending=False, inplace=True)\n",
    "\n",
    "df_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if SHOW_IN_RELEASE:\n",
    "    def learn_fit():    \n",
    "        global version_model\n",
    "        version_model += 1\n",
    "        models = [\n",
    "            {\n",
    "                'name': 'RandomForestClassifier ' + str(version_model),\n",
    "                'model': RandomForestClassifier,\n",
    "                'params': {\n",
    "                    'n_estimators': [200]\n",
    "                },\n",
    "                'preprocessor': pre_RandomForest\n",
    "            }, {\n",
    "                'name': 'LogisticRegression ' + str(version_model),\n",
    "                'model': LogisticRegression,\n",
    "                'params': {\n",
    "                    'max_iter': [100, 200]\n",
    "                },\n",
    "                'preprocessor': pre_LogisticRegression\n",
    "            }, {\n",
    "                'name': 'LinearSVC ' + str(version_model),\n",
    "                'model': LinearSVC,\n",
    "                'params': {\n",
    "                    'max_iter': [800]\n",
    "                },\n",
    "                'cv': 5,\n",
    "                'preprocessor': pre_LinearSVC\n",
    "            }\n",
    "        ]\n",
    "\n",
    "        return try_multi_models(models, False)\n",
    "\n",
    "    learn_load()\n",
    "\n",
    "    def remove_startswith_collumns(texts: list):\n",
    "        def ret(x):\n",
    "            if x == 'HasExpensiveLevel':\n",
    "                return False\n",
    "\n",
    "            for text in texts:\n",
    "                if x.startswith(text):\n",
    "                    return False\n",
    "\n",
    "            return True\n",
    "        return ret\n",
    "\n",
    "    def remove_most_of_collumns(x):\n",
    "        return remove_startswith_collumns(['AttributesCount', 'Cat_', 'ExtraAt_'])(x)\n",
    "\n",
    "    def check2(x):\n",
    "        return remove_startswith_collumns(['AttributesCount'])(x)\n",
    "\n",
    "    def pre_RandomForest(x_sub_train, y_sub_train, x_sub_test, y_sub_test):\n",
    "        fi = list(filter(remove_most_of_collumns, df.columns))\n",
    "        x_sub_train = x_sub_train[fi]\n",
    "        x_sub_test = x_sub_test[fi]\n",
    "\n",
    "        return [x_sub_train, y_sub_train, x_sub_test, y_sub_test]\n",
    "\n",
    "    def pre_LogisticRegression(x_sub_train, y_sub_train, x_sub_test, y_sub_test):\n",
    "        fi = list(filter(check2, df.columns))\n",
    "        x_sub_train = x_sub_train[fi]\n",
    "        x_sub_test = x_sub_test[fi]\n",
    "\n",
    "        scaler = StandardScaler()\n",
    "        x_sub_train = scaler.fit_transform(X=x_sub_train)\n",
    "        x_sub_test = scaler.transform(x_sub_test)\n",
    "\n",
    "        return [x_sub_train, y_sub_train, x_sub_test, y_sub_test]\n",
    "\n",
    "    def pre_LinearSVC(x_sub_train, y_sub_train, x_sub_test, y_sub_test):\n",
    "        fi = list(filter(check2, df.columns))\n",
    "        x_sub_train = x_sub_train[fi]\n",
    "        x_sub_test = x_sub_test[fi]\n",
    "\n",
    "        scaler = StandardScaler()\n",
    "        x_sub_train = scaler.fit_transform(X=x_sub_train)\n",
    "        x_sub_test = scaler.transform(x_sub_test)\n",
    "\n",
    "        return [x_sub_train, y_sub_train, x_sub_test, y_sub_test]\n",
    "\n",
    "    learn_fit()\n",
    "    df_models.sort_values('Score', ascending=False, inplace=True)\n",
    "    df_models = df_models.dropna(subset=['Score'])\n",
    "\n",
    "df_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if SHOW_IN_RELEASE:\n",
    "    def learn_fit():    \n",
    "        global version_model\n",
    "        version_model += 1\n",
    "        models = [\n",
    "            {\n",
    "                'name': 'RandomForestClassifier ' + str(version_model),\n",
    "                'model': RandomForestClassifier,\n",
    "                'params': {\n",
    "                    'n_estimators': [200]\n",
    "                },\n",
    "                'preprocessor': pre_RandomForest\n",
    "            }, {\n",
    "                'name': 'LogisticRegression ' + str(version_model),\n",
    "                'model': LogisticRegression,\n",
    "                'params': {\n",
    "                    'max_iter': [100, 200]\n",
    "                },\n",
    "                'preprocessor': pre_LogisticRegression\n",
    "            }, {\n",
    "                'name': 'LinearSVC ' + str(version_model),\n",
    "                'model': LinearSVC,\n",
    "                'params': {\n",
    "                    'max_iter': [800]\n",
    "                },\n",
    "                'cv': 5,\n",
    "                'preprocessor': pre_LinearSVC\n",
    "            }\n",
    "        ]\n",
    "\n",
    "        return try_multi_models(models, False)\n",
    "\n",
    "    learn_load()\n",
    "\n",
    "    def remove_startswith_collumns(texts: list):\n",
    "        def ret(x):\n",
    "            if x == 'HasExpensiveLevel':\n",
    "                return False\n",
    "\n",
    "            for text in texts:\n",
    "                if x.startswith(text):\n",
    "                    return False\n",
    "\n",
    "            return True\n",
    "        return ret\n",
    "\n",
    "    def remove_most_of_collumns(x):\n",
    "        return remove_startswith_collumns(['AttributesCount', 'WeeklyBreaks', 'Cat_', 'ExtraAt_'])(x)\n",
    "\n",
    "    def check2(x):\n",
    "        return remove_startswith_collumns(['AttributesCount', 'WeeklyBreaks'])(x)\n",
    "\n",
    "    def pre_RandomForest(x_sub_train, y_sub_train, x_sub_test, y_sub_test):\n",
    "        fi = list(filter(remove_most_of_collumns, df.columns))\n",
    "        x_sub_train = x_sub_train[fi]\n",
    "        x_sub_test = x_sub_test[fi]\n",
    "\n",
    "        return [x_sub_train, y_sub_train, x_sub_test, y_sub_test]\n",
    "\n",
    "    def pre_LogisticRegression(x_sub_train, y_sub_train, x_sub_test, y_sub_test):\n",
    "        fi = list(filter(check2, df.columns))\n",
    "        x_sub_train = x_sub_train[fi]\n",
    "        x_sub_test = x_sub_test[fi]\n",
    "\n",
    "        scaler = StandardScaler()\n",
    "        x_sub_train = scaler.fit_transform(X=x_sub_train)\n",
    "        x_sub_test = scaler.transform(x_sub_test)\n",
    "\n",
    "        return [x_sub_train, y_sub_train, x_sub_test, y_sub_test]\n",
    "\n",
    "    def pre_LinearSVC(x_sub_train, y_sub_train, x_sub_test, y_sub_test):\n",
    "        fi = list(filter(check2, df.columns))\n",
    "        x_sub_train = x_sub_train[fi]\n",
    "        x_sub_test = x_sub_test[fi]\n",
    "\n",
    "        scaler = StandardScaler()\n",
    "        x_sub_train = scaler.fit_transform(X=x_sub_train)\n",
    "        x_sub_test = scaler.transform(x_sub_test)\n",
    "\n",
    "        return [x_sub_train, y_sub_train, x_sub_test, y_sub_test]\n",
    "\n",
    "    learn_fit()\n",
    "    df_models.sort_values('Score', ascending=False, inplace=True)\n",
    "    df_models = df_models.dropna(subset=['Score'])\n",
    "\n",
    "df_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if SHOW_IN_RELEASE:\n",
    "    def learn_fit():    \n",
    "        global version_model\n",
    "        version_model += 1\n",
    "        models = [\n",
    "            {\n",
    "                'name': 'RandomForestClassifier ' + str(version_model),\n",
    "                'model': RandomForestClassifier,\n",
    "                'params': {\n",
    "                    'n_estimators': [200]\n",
    "                },\n",
    "                'preprocessor': pre_RandomForest\n",
    "            }, {\n",
    "                'name': 'LogisticRegression ' + str(version_model),\n",
    "                'model': LogisticRegression,\n",
    "                'params': {\n",
    "                    'max_iter': [100, 200]\n",
    "                },\n",
    "                'preprocessor': pre_LogisticRegression\n",
    "            }, {\n",
    "                'name': 'LinearSVC ' + str(version_model),\n",
    "                'model': LinearSVC,\n",
    "                'params': {\n",
    "                    'max_iter': [800]\n",
    "                },\n",
    "                'cv': 5,\n",
    "                'preprocessor': pre_LinearSVC\n",
    "            }\n",
    "        ]\n",
    "\n",
    "        return try_multi_models(models, False)\n",
    "\n",
    "    learn_load()\n",
    "\n",
    "    def remove_startswith_collumns(texts: list):\n",
    "        def ret(x):\n",
    "            if x == 'HasExpensiveLevel':\n",
    "                return False\n",
    "\n",
    "            for text in texts:\n",
    "                if x.startswith(text):\n",
    "                    return False\n",
    "\n",
    "            return True\n",
    "        return ret\n",
    "\n",
    "    def remove_most_of_collumns(x):\n",
    "        return remove_startswith_collumns(['AttributesCount', 'WeeklyBreaks', 'QuestionsCount', 'Cat_', 'ExtraAt_'])(x)\n",
    "\n",
    "    def check2(x):\n",
    "        return remove_startswith_collumns(['AttributesCount', 'WeeklyBreaks', 'QuestionsCount'])(x)\n",
    "\n",
    "    def pre_RandomForest(x_sub_train, y_sub_train, x_sub_test, y_sub_test):\n",
    "        fi = list(filter(remove_most_of_collumns, df.columns))\n",
    "        x_sub_train = x_sub_train[fi]\n",
    "        x_sub_test = x_sub_test[fi]\n",
    "\n",
    "        return [x_sub_train, y_sub_train, x_sub_test, y_sub_test]\n",
    "\n",
    "    def pre_LogisticRegression(x_sub_train, y_sub_train, x_sub_test, y_sub_test):\n",
    "        fi = list(filter(check2, df.columns))\n",
    "        x_sub_train = x_sub_train[fi]\n",
    "        x_sub_test = x_sub_test[fi]\n",
    "\n",
    "        scaler = StandardScaler()\n",
    "        x_sub_train = scaler.fit_transform(X=x_sub_train)\n",
    "        x_sub_test = scaler.transform(x_sub_test)\n",
    "\n",
    "        return [x_sub_train, y_sub_train, x_sub_test, y_sub_test]\n",
    "\n",
    "    def pre_LinearSVC(x_sub_train, y_sub_train, x_sub_test, y_sub_test):\n",
    "        fi = list(filter(check2, df.columns))\n",
    "        x_sub_train = x_sub_train[fi]\n",
    "        x_sub_test = x_sub_test[fi]\n",
    "\n",
    "        scaler = StandardScaler()\n",
    "        x_sub_train = scaler.fit_transform(X=x_sub_train)\n",
    "        x_sub_test = scaler.transform(x_sub_test)\n",
    "\n",
    "        return [x_sub_train, y_sub_train, x_sub_test, y_sub_test]\n",
    "\n",
    "    learn_fit()\n",
    "    df_models.sort_values('Score', ascending=False, inplace=True)\n",
    "    df_models = df_models.dropna(subset=['Score'])\n",
    "\n",
    "df_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We created today a wild function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_models.head(3)\n",
    "# RandomForestClassifier: 0.847155 {\"n_estimators\": 200}\n",
    "# LogisticRegression :    0.841404 {\"max_iter\": 200}\n",
    "# LinearSVC:              0.833384 {\"max_iter\": 800}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if SHOW_IN_RELEASE:\n",
    "    def learn_fit():    \n",
    "        global version_model\n",
    "        version_model += 1\n",
    "        models = [\n",
    "            {\n",
    "                'name': 'RandomForestClassifier ' + str(version_model),\n",
    "                'model': RandomForestClassifier,\n",
    "                'params': {\n",
    "                    'n_estimators': [200]\n",
    "                },\n",
    "                'preprocessor': pre_RandomForest\n",
    "            }, {\n",
    "                'name': 'LogisticRegression ' + str(version_model),\n",
    "                'model': LogisticRegression,\n",
    "                'params': {\n",
    "                    'max_iter': [100, 200]\n",
    "                },\n",
    "                'preprocessor': pre_LogisticRegression\n",
    "            }, {\n",
    "                'name': 'LinearSVC ' + str(version_model),\n",
    "                'model': LinearSVC,\n",
    "                'params': {\n",
    "                    'max_iter': [800]\n",
    "                },\n",
    "                'preprocessor': pre_LinearSVC\n",
    "            }\n",
    "        ]\n",
    "\n",
    "        return try_multi_models(models, False)\n",
    "\n",
    "    learn_load()\n",
    "\n",
    "    def remove_startswith_collumns(texts: list):\n",
    "        def ret(x):\n",
    "            if x == 'HasExpensiveLevel':\n",
    "                return False\n",
    "\n",
    "            for text in texts:\n",
    "                if x.startswith(text):\n",
    "                    return False\n",
    "\n",
    "            return True\n",
    "        return ret\n",
    "    \n",
    "    sp_collumns = ['AttributesCount', 'WeeklyBreaks', 'QuestionsCount', 'HasWebsite', 'Photos']\n",
    "\n",
    "    def remove_collumns_for_model_1(x):\n",
    "        return remove_startswith_collumns(sp_collumns + ['SubCategoriesCount', 'Cat_', 'ExtraAt_'])(x)\n",
    "\n",
    "    def remove_collumns_for_model_2(x):\n",
    "        return remove_startswith_collumns(sp_collumns + [])(x)\n",
    "    \n",
    "    def remove_collumns_for_model_3(x):\n",
    "        return remove_startswith_collumns(sp_collumns + [])(x)\n",
    "\n",
    "    def pre_RandomForest(x_sub_train, y_sub_train, x_sub_test, y_sub_test):\n",
    "        fi = list(filter(remove_collumns_for_model_1, df.columns))\n",
    "        x_sub_train = x_sub_train[fi]\n",
    "        x_sub_test = x_sub_test[fi]\n",
    "\n",
    "        return [x_sub_train, y_sub_train, x_sub_test, y_sub_test]\n",
    "\n",
    "    def pre_LogisticRegression(x_sub_train, y_sub_train, x_sub_test, y_sub_test):\n",
    "        fi = list(filter(remove_collumns_for_model_2, df.columns))\n",
    "        x_sub_train = x_sub_train[fi]\n",
    "        x_sub_test = x_sub_test[fi]\n",
    "\n",
    "        scaler = StandardScaler()\n",
    "        x_sub_train = scaler.fit_transform(X=x_sub_train)\n",
    "        x_sub_test = scaler.transform(x_sub_test)\n",
    "\n",
    "        return [x_sub_train, y_sub_train, x_sub_test, y_sub_test]\n",
    "\n",
    "    def pre_LinearSVC(x_sub_train, y_sub_train, x_sub_test, y_sub_test):\n",
    "        fi = list(filter(remove_collumns_for_model_3, df.columns))\n",
    "        x_sub_train = x_sub_train[fi]\n",
    "        x_sub_test = x_sub_test[fi]\n",
    "\n",
    "        scaler = StandardScaler()\n",
    "        x_sub_train = scaler.fit_transform(X=x_sub_train)\n",
    "        x_sub_test = scaler.transform(x_sub_test)\n",
    "\n",
    "        return [x_sub_train, y_sub_train, x_sub_test, y_sub_test]\n",
    "\n",
    "    learn_fit()\n",
    "    df_models.sort_values('Score', ascending=False, inplace=True)\n",
    "    df_models = df_models.dropna(subset=['Score'])\n",
    "\n",
    "# Impotents: Claimed, Stars, Reviews, Photos\n",
    "df_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if SHOW_IN_RELEASE:\n",
    "    def learn_fit():    \n",
    "        global version_model\n",
    "        version_model += 1\n",
    "        models = [\n",
    "            {\n",
    "                'name': 'RandomForestClassifier ' + str(version_model),\n",
    "                'model': RandomForestClassifier,\n",
    "                'params': {\n",
    "                    'n_estimators': [200]\n",
    "                },\n",
    "                'preprocessor': pre_RandomForest\n",
    "            }, {\n",
    "                'name': 'LogisticRegression ' + str(version_model),\n",
    "                'model': LogisticRegression,\n",
    "                'params': {\n",
    "                    'max_iter': [100, 200]\n",
    "                },\n",
    "                'preprocessor': pre_LogisticRegression\n",
    "            }, {\n",
    "                'name': 'LinearSVC ' + str(version_model),\n",
    "                'model': LinearSVC,\n",
    "                'params': {\n",
    "                    'max_iter': [800]\n",
    "                },\n",
    "                'preprocessor': pre_LinearSVC\n",
    "            }\n",
    "        ]\n",
    "\n",
    "        return try_multi_models(models, False)\n",
    "\n",
    "    learn_load()\n",
    "\n",
    "    def remove_startswith_collumns(texts: list):\n",
    "        def ret(x):\n",
    "            if x == 'HasExpensiveLevel':\n",
    "                return False\n",
    "\n",
    "            for text in texts:\n",
    "                if x.startswith(text):\n",
    "                    return False\n",
    "\n",
    "            return True\n",
    "        return ret\n",
    "    \n",
    "    sp_collumns = ['AttributesCount', 'WeeklyBreaks', 'QuestionsCount', 'HasWebsite', 'Photos']\n",
    "\n",
    "    def remove_collumns_for_model_1(x):\n",
    "        return remove_startswith_collumns(sp_collumns + ['SubCategoriesCount', 'Cat_', 'ExtraAt_'])(x)\n",
    "\n",
    "    def remove_collumns_for_model_2(x):\n",
    "        return remove_startswith_collumns(sp_collumns + [])(x)\n",
    "    \n",
    "    def remove_collumns_for_model_3(x):\n",
    "        return remove_startswith_collumns(sp_collumns + [])(x)\n",
    "\n",
    "    def pre_RandomForest(x_sub_train, y_sub_train, x_sub_test, y_sub_test):\n",
    "        fi = list(filter(remove_collumns_for_model_1, df.columns))\n",
    "        x_sub_train = x_sub_train[fi]\n",
    "        x_sub_test = x_sub_test[fi]\n",
    "\n",
    "        return [x_sub_train, y_sub_train, x_sub_test, y_sub_test]\n",
    "\n",
    "    def pre_LogisticRegression(x_sub_train, y_sub_train, x_sub_test, y_sub_test):\n",
    "        fi = list(filter(remove_collumns_for_model_2, df.columns))\n",
    "        x_sub_train = x_sub_train[fi]\n",
    "        x_sub_test = x_sub_test[fi]\n",
    "\n",
    "        scaler = StandardScaler()\n",
    "        x_sub_train = scaler.fit_transform(X=x_sub_train)\n",
    "        x_sub_test = scaler.transform(x_sub_test)\n",
    "\n",
    "        return [x_sub_train, y_sub_train, x_sub_test, y_sub_test]\n",
    "\n",
    "    def pre_LinearSVC(x_sub_train, y_sub_train, x_sub_test, y_sub_test):\n",
    "        fi = list(filter(remove_collumns_for_model_3, df.columns))\n",
    "        x_sub_train = x_sub_train[fi]\n",
    "        x_sub_test = x_sub_test[fi]\n",
    "\n",
    "        scaler = StandardScaler()\n",
    "        x_sub_train = scaler.fit_transform(X=x_sub_train)\n",
    "        x_sub_test = scaler.transform(x_sub_test)\n",
    "\n",
    "        return [x_sub_train, y_sub_train, x_sub_test, y_sub_test]\n",
    "\n",
    "    learn_fit()\n",
    "    df_models.sort_values('Score', ascending=False, inplace=True)\n",
    "    df_models = df_models.dropna(subset=['Score'])\n",
    "\n",
    "# Impotents: Claimed, Stars, Reviews, Photos\n",
    "df_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_features = 48\n",
    "if SHOW_IN_RELEASE:\n",
    "    def remove_startswith_collumns(texts: list):\n",
    "        def ret(x):\n",
    "            if x == 'HasExpensiveLevel':\n",
    "                return False\n",
    "            for text in texts:\n",
    "                if x.startswith(text):\n",
    "                    return False\n",
    "\n",
    "            return True\n",
    "        return ret\n",
    "\n",
    "    def remove_collumns_for_model_RandomForest(x):\n",
    "        return remove_startswith_collumns(sp_collumns + ['SubCategoriesCount', 'Cat_', 'ExtraAt_'])(x)\n",
    "\n",
    "    def pre_RandomForest():\n",
    "        features = list(filter(remove_collumns_for_model_RandomForest, df.columns))\n",
    "\n",
    "        return len(features)\n",
    "    n_features = pre_RandomForest()\n",
    "\n",
    "n_features\n",
    "\n",
    "int(math.sqrt(n_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if SHOW_IN_RELEASE:\n",
    "    n_features = 48\n",
    "    \n",
    "    def learn_fit():    \n",
    "        global version_model\n",
    "        version_model += 1\n",
    "        models = [\n",
    "            {\n",
    "                'name': 'RandomForestClassifier ' + str(version_model),\n",
    "                'model': RandomForestClassifier,\n",
    "                'params': {\n",
    "                    'n_estimators': [200],\n",
    "                    'max_features': [\n",
    "                        int(math.sqrt(n_features)) - 2,\n",
    "                        int(math.sqrt(n_features)),\n",
    "                        int(math.log2(n_features)),\n",
    "                        int(n_features)\n",
    "                    ]\n",
    "                },\n",
    "                'preprocessor': pre_RandomForest,\n",
    "                'selected': True\n",
    "            }\n",
    "        ]\n",
    "\n",
    "        return try_multi_models(models, False)\n",
    "\n",
    "    learn_load()\n",
    "\n",
    "    def remove_startswith_collumns(texts: list):\n",
    "        def ret(x):\n",
    "            if x == 'HasExpensiveLevel':\n",
    "                return False\n",
    "\n",
    "            for text in texts:\n",
    "                if x.startswith(text):\n",
    "                    return False\n",
    "\n",
    "            return True\n",
    "        return ret\n",
    "    \n",
    "    sp_collumns = ['AttributesCount', 'WeeklyBreaks', 'QuestionsCount', 'HasWebsite', 'Photos']\n",
    "\n",
    "    def remove_collumns_for_model_1(x):\n",
    "        return remove_startswith_collumns(sp_collumns + ['SubCategoriesCount', 'Cat_', 'ExtraAt_'])(x)\n",
    "\n",
    "    def remove_collumns_for_model_2(x):\n",
    "        return remove_startswith_collumns(sp_collumns + [])(x)\n",
    "    \n",
    "    def remove_collumns_for_model_3(x):\n",
    "        return remove_startswith_collumns(sp_collumns + [])(x)\n",
    "\n",
    "    def pre_RandomForest(x_sub_train, y_sub_train, x_sub_test, y_sub_test):\n",
    "        features = list(filter(remove_collumns_for_model_1, df.columns))\n",
    "        x_sub_train = x_sub_train[features]\n",
    "        x_sub_test = x_sub_test[features]\n",
    "\n",
    "        return [x_sub_train, y_sub_train, x_sub_test, y_sub_test]\n",
    "\n",
    "    def pre_LogisticRegression(x_sub_train, y_sub_train, x_sub_test, y_sub_test):\n",
    "        features = list(filter(remove_collumns_for_model_2, df.columns))\n",
    "        x_sub_train = x_sub_train[features]\n",
    "        x_sub_test = x_sub_test[features]\n",
    "\n",
    "        scaler = StandardScaler()\n",
    "        x_sub_train = scaler.fit_transform(X=x_sub_train)\n",
    "        x_sub_test = scaler.transform(x_sub_test)\n",
    "\n",
    "        return [x_sub_train, y_sub_train, x_sub_test, y_sub_test]\n",
    "\n",
    "    def pre_LinearSVC(x_sub_train, y_sub_train, x_sub_test, y_sub_test):\n",
    "        features = list(filter(remove_collumns_for_model_3, df.columns))\n",
    "        x_sub_train = x_sub_train[features]\n",
    "        x_sub_test = x_sub_test[features]\n",
    "\n",
    "        scaler = StandardScaler()\n",
    "        x_sub_train = scaler.fit_transform(X=x_sub_train)\n",
    "        x_sub_test = scaler.transform(x_sub_test)\n",
    "\n",
    "        return [x_sub_train, y_sub_train, x_sub_test, y_sub_test]\n",
    "\n",
    "    ret = learn_fit()\n",
    "    df_models.sort_values('Score', ascending=False, inplace=True)\n",
    "    df_models = df_models.dropna(subset=['Score'])\n",
    "\n",
    "# Impotents: Claimed, Stars, Reviews, Photos\n",
    "df_models\n",
    "ret[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if SHOW_IN_RELEASE:\n",
    "    n_features = 48\n",
    "    \n",
    "    def learn_fit():    \n",
    "        global version_model\n",
    "        version_model += 1\n",
    "        models = [\n",
    "            {\n",
    "                'name': 'RandomForestClassifier ' + str(version_model),\n",
    "                'model': RandomForestClassifier,\n",
    "                'params': {\n",
    "                    'n_estimators': [200],\n",
    "                    'max_features': [1, 2, 3, 6, 9, 10, 11],\n",
    "                    'max_depth': [1, 2, 3, 6, 9, 10, 11],\n",
    "                    'min_samples_split': [1, 2, 3]\n",
    "                },\n",
    "                'preprocessor': pre_RandomForest,\n",
    "                'selected': True\n",
    "            }\n",
    "        ]\n",
    "\n",
    "        return try_multi_models(models, False)\n",
    "\n",
    "    learn_load()\n",
    "\n",
    "    def remove_startswith_collumns(texts: list):\n",
    "        def ret(x):\n",
    "            if x == 'HasExpensiveLevel':\n",
    "                return False\n",
    "\n",
    "            for text in texts:\n",
    "                if x.startswith(text):\n",
    "                    return False\n",
    "\n",
    "            return True\n",
    "        return ret\n",
    "    \n",
    "    sp_collumns = ['AttributesCount', 'WeeklyBreaks', 'QuestionsCount', 'HasWebsite', 'Photos']\n",
    "\n",
    "    def remove_collumns_for_model_1(x):\n",
    "        return remove_startswith_collumns(sp_collumns + ['SubCategoriesCount', 'Cat_', 'ExtraAt_'])(x)\n",
    "\n",
    "    def remove_collumns_for_model_2(x):\n",
    "        return remove_startswith_collumns(sp_collumns + [])(x)\n",
    "    \n",
    "    def remove_collumns_for_model_3(x):\n",
    "        return remove_startswith_collumns(sp_collumns + [])(x)\n",
    "\n",
    "    def pre_RandomForest(x_sub_train, y_sub_train, x_sub_test, y_sub_test):\n",
    "        features = list(filter(remove_collumns_for_model_1, df.columns))\n",
    "        x_sub_train = x_sub_train[features]\n",
    "        x_sub_test = x_sub_test[features]\n",
    "\n",
    "        return [x_sub_train, y_sub_train, x_sub_test, y_sub_test]\n",
    "\n",
    "    def pre_LogisticRegression(x_sub_train, y_sub_train, x_sub_test, y_sub_test):\n",
    "        features = list(filter(remove_collumns_for_model_2, df.columns))\n",
    "        x_sub_train = x_sub_train[features]\n",
    "        x_sub_test = x_sub_test[features]\n",
    "\n",
    "        scaler = StandardScaler()\n",
    "        x_sub_train = scaler.fit_transform(X=x_sub_train)\n",
    "        x_sub_test = scaler.transform(x_sub_test)\n",
    "\n",
    "        return [x_sub_train, y_sub_train, x_sub_test, y_sub_test]\n",
    "\n",
    "    def pre_LinearSVC(x_sub_train, y_sub_train, x_sub_test, y_sub_test):\n",
    "        features = list(filter(remove_collumns_for_model_3, df.columns))\n",
    "        x_sub_train = x_sub_train[features]\n",
    "        x_sub_test = x_sub_test[features]\n",
    "\n",
    "        scaler = StandardScaler()\n",
    "        x_sub_train = scaler.fit_transform(X=x_sub_train)\n",
    "        x_sub_test = scaler.transform(x_sub_test)\n",
    "\n",
    "        return [x_sub_train, y_sub_train, x_sub_test, y_sub_test]\n",
    "\n",
    "    ret = learn_fit()\n",
    "    df_models.sort_values('Score', ascending=False, inplace=True)\n",
    "    df_models = df_models.dropna(subset=['Score'])\n",
    "\n",
    "# Impotents: Claimed, Stars, Reviews, Photos\n",
    "df_models\n",
    "ret[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if SHOW_IN_RELEASE:\n",
    "    n_features = 48\n",
    "    \n",
    "    def learn_fit():    \n",
    "        global version_model\n",
    "        version_model += 1\n",
    "        models = [\n",
    "            {\n",
    "                'name': 'RandomForestClassifier ' + str(version_model),\n",
    "                'model': RandomForestClassifier,\n",
    "                'params': {\n",
    "                    'n_estimators': [200],\n",
    "                    'max_features': [6],\n",
    "                    'max_depth': range(10, 20),\n",
    "                    'min_samples_split': [2]\n",
    "                },\n",
    "                'preprocessor': pre_RandomForest,\n",
    "                'selected': True\n",
    "            }\n",
    "        ]\n",
    "\n",
    "        return try_multi_models(models, False)\n",
    "\n",
    "    learn_load()\n",
    "\n",
    "    def remove_startswith_collumns(texts: list):\n",
    "        def ret(x):\n",
    "            if x == 'HasExpensiveLevel':\n",
    "                return False\n",
    "\n",
    "            for text in texts:\n",
    "                if x.startswith(text):\n",
    "                    return False\n",
    "\n",
    "            return True\n",
    "        return ret\n",
    "    \n",
    "    sp_collumns = ['AttributesCount', 'WeeklyBreaks', 'QuestionsCount', 'HasWebsite', 'Photos']\n",
    "\n",
    "    def remove_collumns_for_model_1(x):\n",
    "        return remove_startswith_collumns(sp_collumns + ['SubCategoriesCount', 'Cat_', 'ExtraAt_'])(x)\n",
    "\n",
    "    def remove_collumns_for_model_2(x):\n",
    "        return remove_startswith_collumns(sp_collumns + [])(x)\n",
    "    \n",
    "    def remove_collumns_for_model_3(x):\n",
    "        return remove_startswith_collumns(sp_collumns + [])(x)\n",
    "\n",
    "    def pre_RandomForest(x_sub_train, y_sub_train, x_sub_test, y_sub_test):\n",
    "        features = list(filter(remove_collumns_for_model_1, df.columns))\n",
    "        x_sub_train = x_sub_train[features]\n",
    "        x_sub_test = x_sub_test[features]\n",
    "\n",
    "        return [x_sub_train, y_sub_train, x_sub_test, y_sub_test]\n",
    "\n",
    "    def pre_LogisticRegression(x_sub_train, y_sub_train, x_sub_test, y_sub_test):\n",
    "        features = list(filter(remove_collumns_for_model_2, df.columns))\n",
    "        x_sub_train = x_sub_train[features]\n",
    "        x_sub_test = x_sub_test[features]\n",
    "\n",
    "        scaler = StandardScaler()\n",
    "        x_sub_train = scaler.fit_transform(X=x_sub_train)\n",
    "        x_sub_test = scaler.transform(x_sub_test)\n",
    "\n",
    "        return [x_sub_train, y_sub_train, x_sub_test, y_sub_test]\n",
    "\n",
    "    def pre_LinearSVC(x_sub_train, y_sub_train, x_sub_test, y_sub_test):\n",
    "        features = list(filter(remove_collumns_for_model_3, df.columns))\n",
    "        x_sub_train = x_sub_train[features]\n",
    "        x_sub_test = x_sub_test[features]\n",
    "\n",
    "        scaler = StandardScaler()\n",
    "        x_sub_train = scaler.fit_transform(X=x_sub_train)\n",
    "        x_sub_test = scaler.transform(x_sub_test)\n",
    "\n",
    "        return [x_sub_train, y_sub_train, x_sub_test, y_sub_test]\n",
    "\n",
    "    ret = learn_fit()\n",
    "    df_models.sort_values('Score', ascending=False, inplace=True)\n",
    "    df_models = df_models.dropna(subset=['Score'])\n",
    "\n",
    "# Impotents: Claimed, Stars, Reviews, Photos\n",
    "df_models\n",
    "ret[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if SHOW_IN_RELEASE:\n",
    "    n_features = 48\n",
    "    \n",
    "    def learn_fit():    \n",
    "        global version_model\n",
    "        version_model += 1\n",
    "        models = [\n",
    "            {\n",
    "                'name': 'RandomForestClassifier ' + str(version_model),\n",
    "                'model': RandomForestClassifier,\n",
    "                'params': {\n",
    "                    'n_estimators': [200],\n",
    "                    'max_features': [6]\n",
    "                },\n",
    "                'preprocessor': pre_RandomForest\n",
    "            }\n",
    "        ]\n",
    "\n",
    "        return try_multi_models(models, False)\n",
    "\n",
    "    learn_load()\n",
    "\n",
    "    def remove_startswith_collumns(texts: list):\n",
    "        def ret(x):\n",
    "            if x == 'HasExpensiveLevel':\n",
    "                return False\n",
    "\n",
    "            for text in texts:\n",
    "                if x.startswith(text):\n",
    "                    return False\n",
    "\n",
    "            return True\n",
    "        return ret\n",
    "    \n",
    "    sp_collumns = ['AttributesCount', 'WeeklyBreaks', 'QuestionsCount', 'HasWebsite', 'Photos']\n",
    "\n",
    "    def remove_collumns_for_model_1(x):\n",
    "        return remove_startswith_collumns(sp_collumns + ['SubCategoriesCount', 'Cat_', 'ExtraAt_'])(x)\n",
    "\n",
    "    def remove_collumns_for_model_2(x):\n",
    "        return remove_startswith_collumns(sp_collumns + [])(x)\n",
    "    \n",
    "    def remove_collumns_for_model_3(x):\n",
    "        return remove_startswith_collumns(sp_collumns + [])(x)\n",
    "\n",
    "    def pre_RandomForest(x_sub_train, y_sub_train, x_sub_test, y_sub_test):\n",
    "        features = list(filter(remove_collumns_for_model_1, df.columns))\n",
    "        x_sub_train = x_sub_train[features]\n",
    "        x_sub_test = x_sub_test[features]\n",
    "\n",
    "        return [x_sub_train, y_sub_train, x_sub_test, y_sub_test]\n",
    "\n",
    "    def pre_LogisticRegression(x_sub_train, y_sub_train, x_sub_test, y_sub_test):\n",
    "        features = list(filter(remove_collumns_for_model_2, df.columns))\n",
    "        x_sub_train = x_sub_train[features]\n",
    "        x_sub_test = x_sub_test[features]\n",
    "\n",
    "        scaler = StandardScaler()\n",
    "        x_sub_train = scaler.fit_transform(X=x_sub_train)\n",
    "        x_sub_test = scaler.transform(x_sub_test)\n",
    "\n",
    "        return [x_sub_train, y_sub_train, x_sub_test, y_sub_test]\n",
    "\n",
    "    def pre_LinearSVC(x_sub_train, y_sub_train, x_sub_test, y_sub_test):\n",
    "        features = list(filter(remove_collumns_for_model_3, df.columns))\n",
    "        x_sub_train = x_sub_train[features]\n",
    "        x_sub_test = x_sub_test[features]\n",
    "\n",
    "        scaler = StandardScaler()\n",
    "        x_sub_train = scaler.fit_transform(X=x_sub_train)\n",
    "        x_sub_test = scaler.transform(x_sub_test)\n",
    "\n",
    "        return [x_sub_train, y_sub_train, x_sub_test, y_sub_test]\n",
    "\n",
    "    learn_fit()\n",
    "    df_models.sort_values('Score', ascending=False, inplace=True)\n",
    "    df_models = df_models.dropna(subset=['Score'])\n",
    "\n",
    "# Impotents: Claimed, Stars, Reviews, Photos\n",
    "df_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_finale_test, y_train, y_finale_test = train_test_split(X, Y, test_size=0.03, random_state=70)\n",
    "x_sub_train, x_sub_test, y_sub_train, y_sub_test = train_test_split(x_train, y_train, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Createing the model based Random Forest\n",
    "def remove_startswith_collumns(texts: list):\n",
    "    def ret(x):\n",
    "        if x == 'HasExpensiveLevel':\n",
    "                return False\n",
    "\n",
    "        for text in texts:\n",
    "            if x.startswith(text):\n",
    "                return False\n",
    "\n",
    "        return True\n",
    "    return ret\n",
    "        \n",
    "def remove_collumns_for_model(x):\n",
    "    sp_collumns = ['AttributesCount', 'WeeklyBreaks', 'QuestionsCount', 'HasWebsite', 'Photos']\n",
    "    return remove_startswith_collumns(sp_collumns + ['SubCategoriesCount', 'Cat_', 'ExtraAt_'])(x)\n",
    "    \n",
    "    \n",
    "def preprocessor(x_sub_train, y_sub_train, x_sub_test, y_sub_test):\n",
    "    features = list(filter(remove_collumns_for_model, df.columns))\n",
    "    x_sub_train = x_sub_train[features]\n",
    "    x_sub_test = x_sub_test[features]\n",
    "    return [x_sub_train, y_sub_train, x_sub_test, y_sub_test]\n",
    "\n",
    "rfc = RandomForestClassifier(n_estimators=200, max_features=10)\n",
    "\n",
    "x_sub_train, y_sub_train, x_sub_test, y_sub_test = preprocessor(x_sub_train, y_sub_train, x_sub_test, y_sub_test)\n",
    "\n",
    "print(\"Fit: \")\n",
    "rfc.fit(x_sub_train, y_sub_train)\n",
    "\n",
    "score = rfc.score(x_sub_test, y_sub_test)\n",
    "print(\"Score: \", score)\n",
    "\n",
    "# Score (Full Data):  0.8559322033898306\n",
    "# Score            :  0.8471549636803875\n",
    "# max_features=10\n",
    "# n_estimators=200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_finale_test, y_train, y_finale_test = train_test_split(X, Y, test_size=0.03, random_state=70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final Test\n",
    "def remove_startswith_collumns(texts: list):\n",
    "    def ret(x):\n",
    "        if x == 'HasExpensiveLevel':\n",
    "                return False\n",
    "\n",
    "        for text in texts:\n",
    "            if x.startswith(text):\n",
    "                return False\n",
    "\n",
    "        return True\n",
    "    return ret\n",
    "        \n",
    "def remove_collumns_for_model(x):\n",
    "    sp_collumns = ['AttributesCount', 'WeeklyBreaks', 'QuestionsCount', 'HasWebsite', 'Photos']\n",
    "    return remove_startswith_collumns(sp_collumns + ['SubCategoriesCount', 'Cat_', 'ExtraAt_'])(x)\n",
    "    \n",
    "    \n",
    "def preprocessor(x_sub_train, y_sub_train, x_sub_test, y_sub_test):\n",
    "    features = list(filter(remove_collumns_for_model, df.columns))\n",
    "    x_sub_train = x_sub_train[features]\n",
    "    x_sub_test = x_sub_test[features]\n",
    "    return [x_sub_train, y_sub_train, x_sub_test, y_sub_test]\n",
    "\n",
    "rfc = RandomForestClassifier(n_estimators=200, max_features=10)\n",
    "\n",
    "x_train, y_train, x_finale_test, y_finale_test = preprocessor(x_train, y_train, x_finale_test, y_finale_test)\n",
    "\n",
    "print(\"Fit: \")\n",
    "rfc.fit(x_train, y_train)\n",
    "\n",
    "score = rfc.score(x_finale_test, y_finale_test)\n",
    "print(\"Score: \", score)\n",
    "\n",
    "# Score:  0.8361858190709046"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# END"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
