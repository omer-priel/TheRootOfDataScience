{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# System\n",
    "import os\n",
    "\n",
    "# Web Scraping\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# Data\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# View\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches\n",
    "import seaborn as sns\n",
    "from IPython.display import Image\n",
    "\n",
    "# ML\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn import metrics\n",
    "\n",
    "# ML Models\n",
    "from sklearn.dummy import DummyClassifier\n",
    "\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.svm import OneClassSVM\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Utilities Files\n",
    "def read_csv(name: str, index_label='id') -> pd.DataFrame:\n",
    "    return pd.read_csv('../data/' + name + '.csv', index_col=index_label)\n",
    "\n",
    "\n",
    "def save_csv(df: pd.DataFrame, name: str, index_label='id'):\n",
    "    df.to_csv('../data/' + name + '.csv', index_label=index_label)\n",
    "\n",
    "def show_image(name: str):\n",
    "    return Image(filename= '../images/' + name + '.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Development Flags\n",
    "SHOW_IN_RELEASE = False\n",
    "SHOW_IN_DEVELOPMENT = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "show_image('Sorry')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "show_image('Data_Collectors')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df_original = read_csv('businesses')\n",
    "df_original = df_original.head(5000)\n",
    "\n",
    "df = df_original.copy()\n",
    "\n",
    "df.drop([\"Url\", \"Name\", \"ExpensiveLevel\", \"SubCategories\", \"AttributesHas\"], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "Y = target = df[\"HasExpensiveLevel\"]\n",
    "X = data = df.drop([\"HasExpensiveLevel\"], axis=1)\n",
    "x_train, x_finale_test, y_train, y_finale_test = train_test_split(X, Y, test_size=0.03, random_state=69)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df = df_train = pd.concat([y_train, x_train], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First Visuation for undsending the data\n",
    "\n",
    "# Config\n",
    "legend_colors = ['tab:blue', 'tab:orange']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "target_column = \"HasExpensiveLevel\"\n",
    "target_column_label = \"Is Expensive\"\n",
    "target_column_label_true = \"Is Expensive\"\n",
    "target_column_label_false = \"Is not Expensive\"\n",
    "\n",
    "prime_flag_columns = [\n",
    "    'Claimed', 'HasWebsite'\n",
    "]\n",
    "\n",
    "prime_countable_columns = [\n",
    "    'Stars',\n",
    "    'SubCategoriesCount', 'AttributesCount',\n",
    "    'QuestionsCount', 'WeeklyBreaks', 'WeeklyDays'\n",
    "]\n",
    "prime_non_countable_columns = [\n",
    "     'Reviews', 'Photos',\n",
    "    'WeeklyHours'\n",
    "]\n",
    "\n",
    "prime_columns = prime_flag_columns + prime_countable_columns + prime_non_countable_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Numberic Visuation\n",
    "df[prime_columns + [target_column]].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visuation per column and between columns\n",
    "\n",
    "def disply_count_of_flag_column(column_name: str, column_label: str, true_label: str, false_label: str, labels: list):\n",
    "    global legend_colors, df, target_column\n",
    "    \n",
    "    df_sp = df[[target_column, column_name]]\n",
    "    \n",
    "    count_df = df_sp.groupby([column_name]).count()\n",
    "    \n",
    "    count_true_df = df_sp[df_sp[column_name] == 1].groupby([target_column]).count()\n",
    "    count_false_df = df_sp[df_sp[column_name] == 0].groupby([target_column]).count()\n",
    "    \n",
    "    # Main elements    \n",
    "    fig = plt.figure(figsize = [16, 8])\n",
    "    \n",
    "    fig.suptitle(column_label)\n",
    "    \n",
    "    ax_graf =  fig.add_subplot(1, 3, 1)\n",
    "    ax_true =  fig.add_subplot(1, 3, 2)\n",
    "    ax_false = fig.add_subplot(1, 3, 3) \n",
    "        \n",
    "    # Graf\n",
    "    plt.sca(ax_graf)\n",
    "    ax_graf.bar( [true_label,false_label], count_df[target_column].values)\n",
    "    plt.xlabel(true_label)\n",
    "    plt.ylabel(\"Count\")\n",
    "    \n",
    "    # Pies\n",
    "    plt.sca(ax_true)\n",
    "    plt.title(true_label)\n",
    "    \n",
    "    ax_true.pie(count_true_df[column_name].values,\n",
    "                radius=4,\n",
    "                center=(4, 4),\n",
    "                colors=legend_colors)\n",
    "    \n",
    "    ax_true.set(xlim=(0, 8), ylim=(0, 8))\n",
    "        \n",
    "    plt.sca(ax_false)\n",
    "    plt.title(false_label)\n",
    "    ax_false.pie(count_false_df[column_name].values,\n",
    "                radius=4,\n",
    "                center=(4, 4),\n",
    "                colors=legend_colors)\n",
    "    \n",
    "    ax_false.set(xlim=(0, 8), ylim=(0, 8))\n",
    "    \n",
    "    # show        \n",
    "    handles = []\n",
    "    for i in range(len(labels)):\n",
    "        handles.append(matplotlib.patches.Patch(label=labels[i], color=legend_colors[i]))\n",
    "\n",
    "    fig.legend(handles=handles, loc =\"lower right\")\n",
    "    \n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def disply_atter_per_column(inedexs: list, values: list, columns_label: list):\n",
    "    global legend_colors, target_column, target_column_label\n",
    "    \n",
    "    # Main elements    \n",
    "    fig = plt.figure(figsize = [16, 8])\n",
    "        \n",
    "    for i in range(len(values)):        \n",
    "        value = values[i]\n",
    "        if value is not None:\n",
    "            index = indexs[i]\n",
    "            label = columns_label[i]\n",
    "                    \n",
    "            # Graf\n",
    "            ax_graf =  fig.add_subplot(1, len(values), i+1)\n",
    "        \n",
    "            plt.sca(ax_graf)\n",
    "            plt.plot(index, value)\n",
    "            plt.xlabel(label)\n",
    "            plt.ylabel(target_column_label)\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def disply_mluti_bars(inedexs: list, values: list, indexs_label, values_label, w: int):\n",
    "    global legend_colors\n",
    "    \n",
    "    values += np.full(elements_in_line-len(values)%elements_in_line, None).tolist()\n",
    "    inedexs += np.full(elements_in_line-len(values)%elements_in_line, None).tolist()\n",
    "    \n",
    "    h = int(len(values) / elements_in_line)\n",
    "    \n",
    "    # Main elements \n",
    "    fig = plt.figure(figsize = [16, h * 8])\n",
    "    \n",
    "    gs = fig.add_gridspec(h, w)\n",
    "    \n",
    "    line = 0\n",
    "    while len(values) > 0:\n",
    "        now_values = values[:elements_in_line]\n",
    "        now_inedexs = inedexs[:elements_in_line]\n",
    "                \n",
    "        for i in range(w):        \n",
    "            value = now_values[i]\n",
    "            if value is not None:\n",
    "                index = now_inedexs[i]\n",
    "                value = now_values[i]\n",
    "            \n",
    "                index_label = indexs_label\n",
    "                value_label = values_label\n",
    "                if type(indexs_label) == list:\n",
    "                    index_label = indexs_label[i]\n",
    "            \n",
    "                if type(values_label) == list:\n",
    "                    value_label = values_label[i]\n",
    "            \n",
    "                # Graf\n",
    "                ax_graf = fig.add_subplot(gs[line, i])\n",
    "        \n",
    "                plt.sca(ax_graf)\n",
    "                plt.bar(index, value)\n",
    "                plt.xlabel(index_label)\n",
    "                plt.ylabel(value_label)\n",
    "                \n",
    "        values = values[elements_in_line:]\n",
    "        inedexs = inedexs[elements_in_line:]\n",
    "        \n",
    "        if type(indexs_label) == list:\n",
    "            indexs_label = indexs_label[elements_in_line:]\n",
    "            \n",
    "        if type(values_label) == list:\n",
    "            values_label = values_label[elements_in_line:]\n",
    "        \n",
    "        line += 1\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Shows the average of \"Has Expensive Level\" for every column by value\n",
    "# Average of \"Has Expensive Level\" symbolizes how likely it is to have expensive level\n",
    "\n",
    "if SHOW_IN_DEVELOPMENT:\n",
    "    \n",
    "    printed_columns = prime_countable_columns\n",
    "    atter_name = 'mean'\n",
    "    \n",
    "    elements_in_line = 3\n",
    "    printed_columns += np.full(elements_in_line-len(printed_columns)%elements_in_line, None).tolist()\n",
    "    while len(printed_columns) > 0:\n",
    "        now_columns = printed_columns[:elements_in_line]\n",
    "        indexs = []\n",
    "        values = []\n",
    "        for column in now_columns:\n",
    "            if column is None:\n",
    "                indexs += [None]\n",
    "                values += [None]\n",
    "            else:\n",
    "                atter_df = df[[target_column, column]].groupby([column])\n",
    "                atter_df = getattr(atter_df, atter_name)()\n",
    "            \n",
    "                indexs += [atter_df.index]\n",
    "                values += [atter_df[target_column].values]            \n",
    "        \n",
    "        disply_atter_per_column(indexs, values, printed_columns[:elements_in_line])\n",
    "        printed_columns = printed_columns[elements_in_line:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## calculates the probability based on sections\n",
    "\n",
    "if SHOW_IN_DEVELOPMENT:\n",
    "    \n",
    "    sections=20\n",
    "    atter_name = 'mean'\n",
    "    elements_in_line = 2\n",
    "    printed_columns = prime_non_countable_columns\n",
    "    \n",
    "    printed_columns += np.full(elements_in_line-len(printed_columns)%elements_in_line, None).tolist()\n",
    "    while len(printed_columns) > 0:\n",
    "        now_columns = printed_columns[:elements_in_line]\n",
    "        indexs = []\n",
    "        values = []\n",
    "        for column in now_columns:\n",
    "            if column is None:\n",
    "                indexs += [None]\n",
    "                values += [None]\n",
    "            else:\n",
    "                new_df = df[[target_column, column]].sort_values(column)\n",
    "                length = len(new_df)\n",
    "                new_df[\"Sections\"] = df.index//(length//sections)\n",
    "                # print(new_df[\"Sections\"])\n",
    "                section_name = range(0,100,100//sections)\n",
    "                atter_df = new_df[[target_column, \"Sections\"]].groupby([\"Sections\"])\n",
    "                atter_df = getattr(atter_df, atter_name)()\n",
    "            \n",
    "                indexs += [atter_df.index]\n",
    "                values += [atter_df[target_column].values]            \n",
    "        \n",
    "        disply_atter_per_column(indexs, values, printed_columns[:elements_in_line])\n",
    "        printed_columns = printed_columns[elements_in_line:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shows Claimed\n",
    "\n",
    "if SHOW_IN_DEVELOPMENT: \n",
    "    disply_count_of_flag_column('Claimed', 'Claimed', 'Claimed', 'Unclaimed',\n",
    "                                ['Has Expensive Level', 'Not has Expensive Level'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Has Website\n",
    "\n",
    "if SHOW_IN_DEVELOPMENT:\n",
    "    disply_count_of_flag_column('HasWebsite', 'Has Website', 'Have', 'Not Have',\n",
    "                                [target_column_label_true, target_column_label_false])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Shows how much data we have for each value in each feature\n",
    "\n",
    "if SHOW_IN_DEVELOPMENT:\n",
    "    \n",
    "    printed_columns = prime_countable_columns + prime_non_countable_columns    \n",
    "    elements_in_line = 3\n",
    "    indexs = []\n",
    "    values = []\n",
    "    for column in printed_columns:\n",
    "        if column is not None:\n",
    "            count_df = df[[target_column, column]].groupby([column]).count()\n",
    "            \n",
    "            indexs += [count_df.index]\n",
    "            values += [count_df[target_column].values.tolist()]            \n",
    "    \n",
    "    disply_mluti_bars(indexs, values, printed_columns, 'Count', elements_in_line)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if SHOW_IN_DEVELOPMENT:\n",
    "    \n",
    "    printed_columns = prime_countable_columns + prime_non_countable_columns    \n",
    "    elements_in_line = 3\n",
    "    printed_columns += np.full(elements_in_line-len(printed_columns)%elements_in_line, None).tolist()\n",
    "    while len(printed_columns) > 0:\n",
    "        now_columns = printed_columns[:elements_in_line]\n",
    "        indexs = []\n",
    "        values = []\n",
    "        for column in now_columns:\n",
    "            if column is None:\n",
    "                indexs += [None]\n",
    "                values += [None]\n",
    "            else:\n",
    "                count_df = df[[target_column, column]].groupby([column]).count()\n",
    "            \n",
    "                indexs += [count_df.index]\n",
    "                values += [count_df[target_column].values.tolist()]            \n",
    "\n",
    "        disply_mluti_bars(indexs, values, printed_columns[:elements_in_line], 'Count', elements_in_line)\n",
    "        printed_columns = printed_columns[elements_in_line:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "if SHOW_IN_DEVELOPMENT:\n",
    "    column_values = df.columns.map(lambda x: x.startswith(\"Cat_\"))\n",
    "    cat_df = df.loc[:, column_values]\n",
    "    categ = cat_df.sum().sort_values()\n",
    "    plt.scatter(categ.index, categ.values)\n",
    "    plt.xlabel(\"categories\")\n",
    "    plt.ylabel(\"how many\")\n",
    "    plt.show()\n",
    "    plt.scatter(categ.head(300).index, categ.head(300).values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "x_sub_train, x_sub_test, y_sub_train, y_sub_test = train_test_split(x_train, y_train, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Create a Simple model base KNN\n",
    "\n",
    "knn = KNeighborsClassifier()\n",
    "\n",
    "knn.fit(x_sub_train, y_sub_train)\n",
    "\n",
    "score = knn.score(x_sub_test, y_sub_test)\n",
    "print(\"Score: \", score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Get the minimum score\n",
    "\n",
    "dummy_modal = DummyClassifier()\n",
    "\n",
    "dummy_modal.fit(x_sub_train, y_sub_train)\n",
    "\n",
    "score = dummy_modal.score(x_sub_test, y_sub_test)\n",
    "print(\"Dummy Modal Score: \", score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df_models = pd.DataFrame({\n",
    "    'Name': [],\n",
    "    'Score': []\n",
    "})\n",
    "\n",
    "def try_multi_models(models):\n",
    "    global x_sub_train, y_sub_train, x_sub_test, y_sub_test\n",
    "    global df_models\n",
    "    \n",
    "    df_models_add = pd.DataFrame({\n",
    "    'Name': np.full(len(models), None),\n",
    "    'Score': np.full(len(models), None)\n",
    "    })\n",
    "        \n",
    "    i = 0\n",
    "    for model in models:\n",
    "        df_models_add.at[i, 'Name'] = model['name']\n",
    "        try:\n",
    "            model['model'].fit(x_sub_train, y_sub_train)\n",
    "            \n",
    "            score = model['model'].score(x_sub_test, y_sub_test)\n",
    "            df_models_add.at[i, 'Score'] = score\n",
    "            print(model['name'] + \" Score: \", score)\n",
    "        except:\n",
    "            print(model['name'] + \" Failed!\")\n",
    "        \n",
    "        i += 1\n",
    "    \n",
    "    df_models = pd.concat([df_models, df_models_add])\n",
    "    df_models.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# First tring\n",
    "\n",
    "models = [\n",
    "    {\n",
    "        'name': 'KNeighborsClassifier',\n",
    "        'model': KNeighborsClassifier()\n",
    "    }, {\n",
    "        'name': 'LogisticRegression',\n",
    "        'model': LogisticRegression()\n",
    "    }, {\n",
    "        'name': 'Lasso',\n",
    "        'model': Lasso()\n",
    "    }, {\n",
    "        'name': 'SVC',\n",
    "        'model': SVC()\n",
    "    }, {\n",
    "        'name': 'LinearSVC',\n",
    "        'model': LinearSVC()\n",
    "    }, {\n",
    "        'name': 'RandomForestClassifier',\n",
    "        'model': RandomForestClassifier()\n",
    "    }\n",
    "]\n",
    "\n",
    "try_multi_models(models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Try svm models\n",
    "\n",
    "models = [\n",
    "    {\n",
    "        'name': 'OneClassSVM',\n",
    "        'model': OneClassSVM(gamma='auto')\n",
    "    }, {\n",
    "        'name': 'SVR',\n",
    "        'model': SVR()\n",
    "    }\n",
    "]\n",
    "\n",
    "try_multi_models(models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Try models like Random Forest\n",
    "\n",
    "models = [\n",
    "    {\n",
    "        'name': 'RandomForestRegressor',\n",
    "        'model': RandomForestRegressor()\n",
    "    }\n",
    "]\n",
    "\n",
    "try_multi_models(models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_models.sort_values('Score', ascending=False, inplace=True)\n",
    "df_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The bast score comes form Random Forest Classifier\n",
    "# https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Learning about VotingClassifier\n",
    "\n",
    "vs = VotingClassifier(estimators=[\n",
    "    ('RandomForestClassifier', RandomForestClassifier()),\n",
    "    ('LogisticRegression', LogisticRegression())\n",
    "])\n",
    "\n",
    "vs.fit(x_sub_train, y_sub_train)\n",
    "\n",
    "score = vs.score(x_sub_test, y_sub_test)\n",
    "print(\"Voting Classifier Score: \", score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_estimators': 700}\n",
      "Score:  0.886232481450948\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n_estimators</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>200</td>\n",
       "      <td>0.857580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>500</td>\n",
       "      <td>0.859505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>300</td>\n",
       "      <td>0.859779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>400</td>\n",
       "      <td>0.860054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>600</td>\n",
       "      <td>0.859780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>700</td>\n",
       "      <td>0.860056</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   n_estimators  Accuracy\n",
       "0           200  0.857580\n",
       "1           500  0.859505\n",
       "2           300  0.859779\n",
       "3           400  0.860054\n",
       "4           600  0.859780\n",
       "5           700  0.860056"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfc = RandomForestClassifier(random_state=1)\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators': [200, 500,300,400,600,700],\n",
    "    \n",
    "}\n",
    "grid_search = GridSearchCV(estimator=rfc, param_grid=param_grid, cv= 5)\n",
    "\n",
    "grid_search.fit(x_sub_train, y_sub_train)\n",
    "\n",
    "print(grid_search.best_params_)\n",
    "\n",
    "score = grid_search.score(x_sub_test, y_sub_test)\n",
    "print(\"Score: \", score)\n",
    "\n",
    "res_as_df = pd.concat([pd.DataFrame(grid_search.cv_results_[\"params\"]), pd.DataFrame(grid_search.cv_results_[\"mean_test_score\"], columns=[\"Accuracy\"])], axis=1)\n",
    "res_as_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
